{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# AmazonBooks – NCF Baseline\n",
    "\n",
    "This notebook trains a Neural Collaborative Filtering (NCF) baseline on the AmazonBooks dataset and evaluates it on a 100-user candidate subset, to be compared later with LLM-based recommenders.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Setup and load data\n",
    "\n",
    "In this section we:\n",
    "\n",
    "1. Set up paths to the `splits/` and `candidates_subset100/` folders.\n",
    "2. Detect the device (CPU / GPU).\n",
    "3. Load:\n",
    "  - `train_indexed.parquet`  (implicit feedback positives)\n",
    "  - `val_targets_indexed.parquet` / `test_targets_indexed.parquet` (ground-truth items)\n",
    "  - `val.parquet` / `test.parquet` (candidate pools for the 100-user subset)\n",
    "- Run basic sanity checks on user and item counts and on the candidate pools.\n"
   ],
   "id": "5eb7b5f8e24fe9ad"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T18:13:57.701010Z",
     "start_time": "2025-12-06T18:13:52.135130Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "BASE   = Path(r\"C:\\Users\\carlk\\OneDrive\\Documents\\uoft\\ECE1508H F\\Project\")\n",
    "SPLITS = BASE / \"splits\"\n",
    "CANDS  = BASE / \"candidates_subset100\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "train_idx = pd.read_parquet(SPLITS / \"train_indexed.parquet\")          # [uid, iid, ts]\n",
    "val_tgt   = pd.read_parquet(CANDS  / \"val_targets_indexed.parquet\")    # [uid, val_item(iid), ts_val]\n",
    "test_tgt  = pd.read_parquet(CANDS  / \"test_targets_indexed.parquet\")   # [uid, test_item(iid), ts_test]\n",
    "\n",
    "cand_val  = pd.read_parquet(CANDS  / \"val.parquet\")                    # [uid, candidates]\n",
    "cand_test = pd.read_parquet(CANDS  / \"test.parquet\")                   # [uid, candidates]\n",
    "\n",
    "print(\"Loaded train_idx:\", train_idx.shape)\n",
    "print(\"Loaded val_tgt  :\", val_tgt.shape)\n",
    "print(\"Loaded test_tgt :\", test_tgt.shape)\n",
    "print(\"Loaded cand_val :\", cand_val.shape)\n",
    "print(\"Loaded cand_test:\", cand_test.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loaded train_idx: (60536, 3)\n",
      "Loaded val_tgt  : (100, 4)\n",
      "Loaded test_tgt : (100, 4)\n",
      "Loaded cand_val : (100, 2)\n",
      "Loaded cand_test: (100, 2)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Inspect the 100-user subset and candidate pools\n",
    "\n",
    "Here I restrict the training data to the 100 users that appear in the validation / test splits and run sanity checks:\n",
    "\n",
    "1. Number of users in train / val / test for the subset.\n",
    "2. Distribution of train positives per user.\n",
    "3. Number of candidate rows per user.\n",
    "4. Verify that validation and test use the same candidate pool.\n",
    "5. Derive `num_users` and `num_items` for the NCF model."
   ],
   "id": "b02fa219ac960958"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T18:13:57.761932Z",
     "start_time": "2025-12-06T18:13:57.739238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "subset_users = sorted(val_tgt[\"uid\"].unique())\n",
    "train_sub = train_idx[train_idx[\"uid\"].isin(subset_users)].copy()\n",
    "\n",
    "print(\"\\n[1] User counts (subset)\")\n",
    "print(\"train users in subset:\", train_sub[\"uid\"].nunique())\n",
    "print(\"val users           :\", val_tgt[\"uid\"].nunique())\n",
    "print(\"test users          :\", test_tgt[\"uid\"].nunique())\n",
    "\n",
    "train_counts = train_sub.groupby(\"uid\")[\"iid\"].nunique()\n",
    "print(\"\\n[2] Train positives per user (subset)\")\n",
    "print(train_counts.describe())\n",
    "print(\"Min train positives per user:\", int(train_counts.min()))\n",
    "print(\"Max train positives per user:\", int(train_counts.max()))\n",
    "\n",
    "print(\"\\n[3] Candidate rows per user\")\n",
    "print(\"val candidate users :\", cand_val[\"uid\"].nunique())\n",
    "print(\"test candidate users:\", cand_test[\"uid\"].nunique())\n",
    "\n",
    "cand_val_sorted  = cand_val.sort_values(\"uid\").reset_index(drop=True)\n",
    "cand_test_sorted = cand_test.sort_values(\"uid\").reset_index(drop=True)\n",
    "\n",
    "same_uid_order = cand_val_sorted[\"uid\"].tolist() == cand_test_sorted[\"uid\"].tolist()\n",
    "val_pools  = cand_val_sorted[\"candidates\"].tolist()\n",
    "test_pools = cand_test_sorted[\"candidates\"].tolist()\n",
    "\n",
    "same_pools = all(np.array_equal(v, t) for v, t in zip(val_pools, test_pools))\n",
    "\n",
    "print(\"\\n[4] Same candidate pool for val & test?\")\n",
    "print(\"same uid order:\", same_uid_order)\n",
    "print(\"same pools   :\", same_pools)\n",
    "\n",
    "num_users = int(train_idx[\"uid\"].max()) + 1\n",
    "num_items = int(train_idx[\"iid\"].max()) + 1\n",
    "\n",
    "print(\"\\nnum_users =\", num_users)\n",
    "print(\"num_items =\", num_items)"
   ],
   "id": "7346c61d7575aac3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1] User counts (subset)\n",
      "train users in subset: 100\n",
      "val users           : 100\n",
      "test users          : 100\n",
      "\n",
      "[2] Train positives per user (subset)\n",
      "count    100.000000\n",
      "mean       4.090000\n",
      "std        0.911154\n",
      "min        3.000000\n",
      "25%        3.000000\n",
      "50%        4.000000\n",
      "75%        5.000000\n",
      "max        5.000000\n",
      "Name: iid, dtype: float64\n",
      "Min train positives per user: 3\n",
      "Max train positives per user: 5\n",
      "\n",
      "[3] Candidate rows per user\n",
      "val candidate users : 100\n",
      "test candidate users: 100\n",
      "\n",
      "[4] Same candidate pool for val & test?\n",
      "same uid order: True\n",
      "same pools   : True\n",
      "\n",
      "num_users = 14064\n",
      "num_items = 18782\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Define the training dataset (implicit feedback with negatives)\n",
    "\n",
    "I define an `NCFDataset` that:\n",
    "\n",
    "1. Takes the positive interactions `df[[\"uid\", \"iid\"]]` for the 100-user subset.\n",
    "2. Pre-computes, for each user, the set of items they have interacted with.\n",
    "3. For every positive (user, item) pair, samples a fixed number of negative items\n",
    "  that the user has not interacted with.\n",
    "\n",
    "The dataset returns batches of:\n",
    "1. user IDs\n",
    "2. item IDs (one positive + several negatives)\n",
    "3. binary labels (1 for positive, 0 for negatives)\n"
   ],
   "id": "dab6729cd6b8f726"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T18:13:57.806954Z",
     "start_time": "2025-12-06T18:13:57.800258Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NCFDataset(Dataset):\n",
    "    def __init__(self, df, num_items, num_neg=4):\n",
    "\n",
    "        self.users     = df[\"uid\"].values.astype(np.int64)\n",
    "        self.items     = df[\"iid\"].values.astype(np.int64)\n",
    "        self.num_items = int(num_items)\n",
    "        self.num_neg   = int(num_neg)\n",
    "\n",
    "        user_pos = {}\n",
    "        for u, i in zip(self.users, self.items):\n",
    "            user_pos.setdefault(int(u), set()).add(int(i))\n",
    "        self.user_pos = user_pos\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        u = int(self.users[idx])\n",
    "        i = int(self.items[idx])\n",
    "\n",
    "        user_list  = [u]\n",
    "        item_list  = [i]\n",
    "        label_list = [1.0]\n",
    "\n",
    "        pos_items = self.user_pos[u]\n",
    "        for _ in range(self.num_neg):\n",
    "            j = np.random.randint(0, self.num_items)\n",
    "\n",
    "            while j in pos_items:\n",
    "                j = np.random.randint(0, self.num_items)\n",
    "            user_list.append(u)\n",
    "            item_list.append(j)\n",
    "            label_list.append(0.0)\n",
    "\n",
    "        return (\n",
    "            torch.tensor(user_list,  dtype=torch.long),\n",
    "            torch.tensor(item_list,  dtype=torch.long),\n",
    "            torch.tensor(label_list, dtype=torch.float32),\n",
    "        )\n"
   ],
   "id": "76a358fbf63296fc",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Define the NCF model\n",
    "\n",
    "I implement a simple Neural Collaborative Filtering (NCF) model:\n",
    "\n",
    "1. Learnable user and item embeddings of size `emb_dim`.\n",
    "2. Concatenate user and item embeddings.\n",
    "3. Pass through a small MLP (`mlp_dims`) with ReLU activations.\n",
    "4. Final linear layer + sigmoid to output a relevance score in `[0, 1]`.\n",
    "\n",
    "This is the baseline recommender that will be compared against LLM-based methods.\n"
   ],
   "id": "57f88646003883cb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T18:13:57.818217Z",
     "start_time": "2025-12-06T18:13:57.813824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NCF(nn.Module):\n",
    "    def __init__(self, num_users, num_items,\n",
    "                 emb_dim=64, mlp_dims=(128, 64, 32)):\n",
    "        super().__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, emb_dim)\n",
    "        self.item_emb = nn.Embedding(num_items, emb_dim)\n",
    "\n",
    "        layers = []\n",
    "        input_dim = emb_dim * 2\n",
    "        for h in mlp_dims:\n",
    "            layers.append(nn.Linear(input_dim, h))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = h\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "        self.out = nn.Linear(input_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        u = self.user_emb(user)\n",
    "        v = self.item_emb(item)\n",
    "        x = torch.cat([u, v], dim=-1)\n",
    "        x = self.mlp(x)\n",
    "        x = self.out(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x.squeeze(-1)"
   ],
   "id": "6bf1c83854aa5994",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Train the NCF baseline\n",
    "\n",
    "I now:\n",
    "\n",
    "1. Build the `NCFDataset` and PyTorch `DataLoader` using the 100-user subset.\n",
    "2. Instantiate the NCF model and an Adam optimizer.\n",
    "3. Train for a small number of epochs using binary cross-entropy loss\n",
    "  on positive + sampled negative items.\n",
    "\n",
    "The printed epoch losses give a quick sanity check that training is converging.\n"
   ],
   "id": "c8d9f54a8306ad35"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-06T18:14:00.121875Z",
     "start_time": "2025-12-06T18:13:57.824309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "BATCH_SIZE   = 512\n",
    "NUM_EPOCHS   = 5\n",
    "NEG_PER_POS  = 4\n",
    "LR           = 1e-3\n",
    "\n",
    "# Build dataset + dataloader using the 100-user subset\n",
    "train_ds = NCFDataset(\n",
    "    train_sub[[\"uid\", \"iid\"]],\n",
    "    num_items=num_items,\n",
    "    num_neg=NEG_PER_POS,\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "model = NCF(num_users=num_users, num_items=num_items).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for users, items, labels in tqdm(train_loader, desc=f\"Epoch {epoch}\"):\n",
    "        # users/items: [batch, 1 + num_neg]\n",
    "        users  = users.view(-1).to(device)\n",
    "        items  = items.view(-1).to(device)\n",
    "        labels = labels.view(-1).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(users, items)\n",
    "        loss  = criterion(preds, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch}: loss = {avg_loss:.4f}\")"
   ],
   "id": "e4c52784d810b242",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00, 13.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss = 0.6728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00, 24.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: loss = 0.6614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00, 32.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: loss = 0.6513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 38.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: loss = 0.6414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00, 34.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: loss = 0.6326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6. Evaluation helper: HitRate / NDCG / Precision@K\n",
    "\n",
    "I define a reusable evaluation function that:\n",
    "\n",
    "1. Joins ground-truth targets with candidate pools.\n",
    "2. Scores all candidate items for each user with the trained NCF model.\n",
    "3. Ranks candidates and computes:\n",
    "  - HitRate@K\n",
    "  - NDCG@K\n",
    "  - Precision@K\n",
    "  - F1@K\n",
    "\n",
    "Users whose ground-truth item is not in the candidate pool are skipped.\n"
   ],
   "id": "41a9fb08c1428a06"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-06T18:14:00.139281Z",
     "start_time": "2025-12-06T18:14:00.130697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def eval_split(model, cand_df, tgt_df, topk=10, max_users=None):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    tgt = tgt_df[[\"uid\", \"iid\"]].rename(columns={\"iid\": \"target_iid\"})\n",
    "    df  = cand_df.merge(tgt, on=\"uid\", how=\"inner\")\n",
    "\n",
    "    if max_users is not None:\n",
    "        df = df.iloc[:max_users]\n",
    "\n",
    "    hits, ndcgs, precs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Eval users\"):\n",
    "            uid    = int(row.uid)\n",
    "            cands  = list(row.candidates)\n",
    "            target = int(row.target_iid)\n",
    "\n",
    "            if target not in cands:\n",
    "                continue\n",
    "\n",
    "            items = torch.tensor(cands, device=device, dtype=torch.long)\n",
    "            users = torch.full_like(items, uid, device=device)\n",
    "\n",
    "            scores      = model(users, items).cpu().numpy()\n",
    "            ranking_idx = np.argsort(-scores)\n",
    "            topk_items  = [cands[i] for i in ranking_idx[:topk]]\n",
    "\n",
    "            hit = int(target in topk_items)\n",
    "            hits.append(hit)\n",
    "\n",
    "            if hit:\n",
    "                rank = topk_items.index(target) + 1\n",
    "                ndcgs.append(1.0 / np.log2(rank + 1))\n",
    "            else:\n",
    "                ndcgs.append(0.0)\n",
    "\n",
    "            precs.append(hit / topk)\n",
    "\n",
    "    if len(hits) == 0:\n",
    "        print(\"No users with target inside candidate pool!\")\n",
    "        return {\"HR\": 0.0, \"NDCG\": 0.0, \"Precision\": 0.0, \"F1\": 0.0}\n",
    "\n",
    "    hr    = float(np.mean(hits))\n",
    "    ndcg  = float(np.mean(ndcgs))\n",
    "    prec  = float(np.mean(precs))\n",
    "    recall = hr\n",
    "    f1    = 2 * prec * recall / (prec + recall) if (prec + recall) > 0 else 0.0\n",
    "\n",
    "    print(f\"Evaluated users: {len(hits)}\")\n",
    "    print(f\"HR@{topk}:       {hr:.4f}\")\n",
    "    print(f\"NDCG@{topk}:     {ndcg:.4f}\")\n",
    "    print(f\"Precision@{topk}: {prec:.4f}\")\n",
    "    print(f\"F1@{topk}:       {f1:.4f}\")\n",
    "\n",
    "    return {\"HR\": hr, \"NDCG\": ndcg, \"Precision\": prec, \"F1\": f1}"
   ],
   "id": "93a3e340a3142cff",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 7. Evaluate on validation and test candidate pools\n",
    "\n",
    "Finally, I evaluate the trained NCF model on:\n",
    "\n",
    "1. The validation candidate pools for the 100-user subset.\n",
    "2. The test candidate pools for the same users.\n",
    "\n",
    "I report the top-10 ranking metrics (HR@10, NDCG@10, Precision@10, F1@10).\n",
    "These results form the NCF baseline that will be compared directly\n",
    "against the LLM-based recommendation approach.\n"
   ],
   "id": "758c2d5603dfb54e"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-06T18:14:00.233668Z",
     "start_time": "2025-12-06T18:14:00.147142Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nValidation\")\n",
    "val_metrics = eval_split(model, cand_val, val_tgt, topk=10)\n",
    "\n",
    "print(\"\\nTest\")\n",
    "test_metrics = eval_split(model, cand_test, test_tgt, topk=10)\n",
    "\n",
    "print(\"\\nVal metrics :\", val_metrics)\n",
    "print(\"Test metrics:\", test_metrics)"
   ],
   "id": "160546279175697a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval users: 100%|██████████| 100/100 [00:00<00:00, 2825.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated users: 100\n",
      "HR@10:       0.1300\n",
      "NDCG@10:     0.0585\n",
      "Precision@10: 0.0130\n",
      "F1@10:       0.0236\n",
      "\n",
      "Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval users: 100%|██████████| 100/100 [00:00<00:00, 2812.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated users: 100\n",
      "HR@10:       0.2300\n",
      "NDCG@10:     0.1072\n",
      "Precision@10: 0.0230\n",
      "F1@10:       0.0418\n",
      "\n",
      "Val metrics : {'HR': 0.13, 'NDCG': 0.058466059117301475, 'Precision': 0.013000000000000001, 'F1': 0.02363636363636364}\n",
      "Test metrics: {'HR': 0.23, 'NDCG': 0.10723639114963507, 'Precision': 0.023000000000000003, 'F1': 0.04181818181818183}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
