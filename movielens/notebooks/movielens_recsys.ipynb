{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epcdolO1Tlw5"
   },
   "source": [
    "### This notebook performs data preprocessing on the MovieLens - 1M dataset to create candidate pools that will be used by both the recommender system and the LLMs to establish equivalent baselines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eithwTf8Tp6-"
   },
   "source": [
    "### 1) Convert ratings.dat to csv for ease of reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote: C:\\Users\\abdul\\ece1508gp\\movielens_dataset\\ratings.csv 1000209\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "RAW = Path(r\"C:\\Users\\abdul\\ece1508gp\\movielens_dataset\")\n",
    "out_csv = RAW / \"ratings.csv\"\n",
    "\n",
    "df = pd.read_csv(\n",
    "    RAW / \"ratings.dat\",\n",
    "    sep=\"::\",\n",
    "    engine=\"python\",\n",
    "    names=[\"userId\", \"movieId\", \"rating\", \"timestamp\"]\n",
    ")\n",
    "df.to_csv(out_csv, index=False)\n",
    "print(\"wrote:\", out_csv, len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Convert movies.dat to readable .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted: C:\\Users\\abdul\\ece1508gp\\movielens_dataset\\movies.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_path  = r\"C:\\Users\\abdul\\ece1508gp\\movielens_dataset\\movies.dat\"\n",
    "output_path = r\"C:\\Users\\abdul\\ece1508gp\\movielens_dataset\\movies.csv\"\n",
    "\n",
    "df = pd.read_csv(\n",
    "    input_path,\n",
    "    sep=\"::\",\n",
    "    engine=\"python\", \n",
    "    header=None,\n",
    "    names=[\"movieId\", \"title\", \"genres\"],\n",
    "    encoding=\"latin-1\" \n",
    ")\n",
    "\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Converted:\", output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Cap ratings to limit only 6 movies per user in total for both test/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limited ratings shape: (30200, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ratings = pd.read_csv(r\"C:\\Users\\abdul\\OneDrive\\Documents\\GitHub\\recsysvsllms\\movielens_dataset\\ratings.csv\")\n",
    "ratings = ratings.sort_values([\"userId\", \"timestamp\"], ascending=[True, False])\n",
    "\n",
    "ratings_limited = ratings.groupby(\"userId\").head(5).reset_index(drop=True)\n",
    "print(\"Limited ratings shape:\", ratings_limited.shape)\n",
    "\n",
    "# rewrite for calling split later on\n",
    "ratings_limited.to_csv(r\"C:\\Users\\abdul\\OneDrive\\Documents\\GitHub\\recsysvsllms\\movielens_dataset\\ratings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executing Time Aware LOO Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Create time-aware leave-one-out split with data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "W_pCAnFf4jnu"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def _detect_ts_unit(ts_series):\n",
    "    vmax = float(ts_series.max())\n",
    "    return \"ms\" if vmax > 1e12 else \"s\"\n",
    "\n",
    "def time_aware_loo_split(\n",
    "    ratings_csv: str,\n",
    "    out_dir: str,\n",
    "    rating_threshold: float = 3.0,\n",
    "    min_positives: int = 3,\n",
    "    also_csv: bool = False,\n",
    "):\n",
    "    out = Path(out_dir); (out / \"splits\").mkdir(parents=True, exist_ok=True)\n",
    "    ratings = pd.read_csv(ratings_csv)\n",
    "\n",
    "    need = {\"userId\",\"movieId\",\"rating\",\"timestamp\"}   #check for missing columns\n",
    "    missing = need - set(ratings.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"ratings.csv missing columns: {missing}\")\n",
    "\n",
    "    unit = _detect_ts_unit(ratings[\"timestamp\"])   # normalize the timestamps and filter out rows where < rating threshold\n",
    "    ratings[\"ts\"] = pd.to_datetime(ratings[\"timestamp\"], unit=unit)\n",
    "\n",
    "    pos = ratings[ratings[\"rating\"] >= rating_threshold].copy()\n",
    "\n",
    "    #drop duplicates and keep only first interaction per user-item\n",
    "    pos = pos.sort_values([\"userId\",\"ts\",\"movieId\"], kind=\"mergesort\")\n",
    "    pos = pos.drop_duplicates([\"userId\",\"movieId\"], keep=\"first\")\n",
    "\n",
    "    pos = pos[pos.groupby(\"userId\")[\"movieId\"].transform(\"size\") >= min_positives].copy()   #filtering for min positives\n",
    "\n",
    "    #rank by time and assign splits, basically last is test, second last is val, rest train\n",
    "    pos[\"n\"] = pos.groupby(\"userId\")[\"movieId\"].transform(\"size\")\n",
    "    pos[\"idx\"] = pos.groupby(\"userId\").cumcount()\n",
    "    pos[\"split\"] = \"train\"\n",
    "    pos.loc[pos[\"idx\"] == pos[\"n\"]-1, \"split\"] = \"test\"\n",
    "    pos.loc[(pos[\"n\"]>=3) & (pos[\"idx\"] == pos[\"n\"]-2), \"split\"] = \"val\"\n",
    "\n",
    "    train = pos[pos[\"split\"]==\"train\"][[\"userId\",\"movieId\",\"ts\"]].reset_index(drop=True)\n",
    "    val_targets  = pos[pos[\"split\"]==\"val\"][[\"userId\",\"movieId\",\"ts\"]].rename(\n",
    "        columns={\"movieId\":\"val_item\",\"ts\":\"ts_val\"}).reset_index(drop=True)\n",
    "    test_targets = pos[pos[\"split\"]==\"test\"][[\"userId\",\"movieId\",\"ts\"]].rename(\n",
    "        columns={\"movieId\":\"test_item\",\"ts\":\"ts_test\"}).reset_index(drop=True)\n",
    "\n",
    "    #building user and item id maps from train set only\n",
    "    uids = pd.DataFrame(sorted(train[\"userId\"].unique()), columns=[\"userId\"])\n",
    "    uids[\"uid\"] = range(len(uids))\n",
    "    iids = pd.DataFrame(sorted(train[\"movieId\"].unique()), columns=[\"movieId\"])\n",
    "    iids[\"iid\"] = range(len(iids))\n",
    "\n",
    "    #creating indexed versions of splits for both easier model training \n",
    "    train_idx = (train.merge(uids, on=\"userId\", how=\"inner\")\n",
    "                      .merge(iids, on=\"movieId\", how=\"inner\"))\n",
    "    val_idx = None\n",
    "    if len(val_targets):\n",
    "        val_idx = (val_targets.merge(uids, on=\"userId\", how=\"inner\")\n",
    "                              .merge(iids, left_on=\"val_item\", right_on=\"movieId\", how=\"left\")\n",
    "                              .drop(columns=[\"movieId\"]))\n",
    "    test_idx = (test_targets.merge(uids, on=\"userId\", how=\"inner\")\n",
    "                               .merge(iids, left_on=\"test_item\", right_on=\"movieId\", how=\"left\")\n",
    "                               .drop(columns=[\"movieId\"]))\n",
    "\n",
    "    #save outputs to local\n",
    "    sp = out / \"splits\"\n",
    "    train.to_parquet(sp / \"train.parquet\", index=False)\n",
    "    if len(val_targets):\n",
    "        val_targets.to_parquet(sp / \"val_targets.parquet\", index=False)\n",
    "    test_targets.to_parquet(sp / \"test_targets.parquet\", index=False)\n",
    "    uids.to_parquet(sp / \"user_id_map.parquet\", index=False)\n",
    "    iids.to_parquet(sp / \"item_id_map.parquet\", index=False)\n",
    "    train_idx.to_parquet(sp / \"train_indexed.parquet\", index=False)\n",
    "    if val_idx is not None:\n",
    "        val_idx.to_parquet(sp / \"val_targets_indexed.parquet\", index=False)\n",
    "    test_idx.to_parquet(sp / \"test_targets_indexed.parquet\", index=False)\n",
    "\n",
    "    if also_csv:\n",
    "        train.to_csv(sp / \"train.csv\", index=False)\n",
    "        if len(val_targets): val_targets.to_csv(sp / \"val_targets.csv\", index=False)\n",
    "        test_targets.to_csv(sp / \"test_targets.csv\", index=False)\n",
    "        uids.to_csv(sp / \"user_id_map.csv\", index=False)\n",
    "        iids.to_csv(sp / \"item_id_map.csv\", index=False)\n",
    "        train_idx.to_csv(sp / \"train_indexed.csv\", index=False)\n",
    "        if val_idx is not None:\n",
    "            val_idx.to_csv(sp / \"val_targets_indexed.csv\", index=False)\n",
    "        test_idx.to_csv(sp / \"test_targets_indexed.csv\", index=False)\n",
    "\n",
    "    # sanity check counts + stats\n",
    "    cold_val = int(val_idx[\"iid\"].isna().sum()) if val_idx is not None and \"iid\" in val_idx else 0\n",
    "    cold_test = int(test_idx[\"iid\"].isna().sum()) if \"iid\" in test_idx else 0\n",
    "    stats = f\"\"\"Time-aware LOO split summary\n",
    "Users (TRAIN map): {len(uids)}\n",
    "Items (TRAIN map): {len(iids)}\n",
    "TRAIN positives  : {len(train)}\n",
    "VAL users        : {len(val_targets[\"userId\"].unique()) if len(val_targets) else 0}\n",
    "TEST users       : {len(test_targets[\"userId\"].unique())}\n",
    "Cold-start VAL items  : {cold_val}\n",
    "Cold-start TEST items : {cold_test}\n",
    "\"\"\"\n",
    "    (sp / \"stats.txt\").write_text(stats, encoding=\"utf-8\")\n",
    "    print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ThfMPG-5Txll"
   },
   "source": [
    "### 2) Actually call the Time Aware LOO Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "boIFiP3OAAgz",
    "outputId": "94890907-82a2-42a9-8279-cff31decd1e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-aware LOO split summary\n",
      "Users (TRAIN map): 4675\n",
      "Items (TRAIN map): 2233\n",
      "TRAIN positives  : 12557\n",
      "VAL users        : 4675\n",
      "TEST users       : 4675\n",
      "Cold-start VAL items  : 289\n",
      "Cold-start TEST items : 303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_aware_loo_split(\n",
    "    ratings_csv=r\"C:\\Users\\abdul\\OneDrive\\Documents\\GitHub\\recsysvsllms\\movielens_dataset\\ratings.csv\",\n",
    "    out_dir=r\"C:\\Users\\abdul\\OneDrive\\Documents\\GitHub\\recsysvsllms\\movielens_dataset\",\n",
    "    rating_threshold=3.0,   #setting to 3 to get more positives\n",
    "    min_positives=4,        \n",
    "    also_csv=True           \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-rj0cuAT4t8"
   },
   "source": [
    "### 3) Load created splits and verify the Users/Items dimensions in splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s6-kBI8_T9Gw"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "SPLITS = Path(r\"C:\\Users\\abdul\\OneDrive\\Documents\\GitHub\\recsysvsllms\\movielens_dataset\\splits\")\n",
    "\n",
    "train = pd.read_parquet(SPLITS / \"train_indexed.parquet\")       \n",
    "val_idx = pd.read_parquet(SPLITS / \"val_targets_indexed.parquet\") \n",
    "test_idx = pd.read_parquet(SPLITS / \"test_targets_indexed.parquet\") \n",
    "\n",
    "U = int(train[\"uid\"].max()) + 1\n",
    "I = int(train[\"iid\"].max()) + 1\n",
    "print(\"users:\", U, \"items:\", I, \"train rows:\", len(train))\n",
    "\n",
    "# generating the actual users×items implicit matrix for als recommender using int32 since Windows was throwing errors with default dtypes \n",
    "rows = train[\"uid\"].to_numpy(dtype=np.int32, copy=False)\n",
    "cols = train[\"iid\"].to_numpy(dtype=np.int32, copy=False)\n",
    "data = np.ones(len(train), dtype=np.float32)\n",
    "\n",
    "R = csr_matrix((data, (rows, cols)), shape=(U, I), dtype=np.float32)\n",
    "\n",
    "#also filtering out the seen items per user for pool generation and evaluation\n",
    "user_seen = train.groupby(\"uid\")[\"iid\"].apply(set).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pool Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FMpEQftzUDUk"
   },
   "source": [
    "### First tool: Using Popularity (popular movies train-only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "8691IfAeUFjl"
   },
   "outputs": [],
   "source": [
    "pop = (\n",
    "    train.groupby(\"iid\").size()\n",
    "         .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "def top_pop_unseen(u_seen, P=50):\n",
    "    out = []\n",
    "    for iid in pop.index:\n",
    "        if iid not in u_seen:\n",
    "            out.append(int(iid))\n",
    "            if len(out) >= P:\n",
    "                break\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second tool: Using item-item k-nearest neighbors (w sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn item–item fitted on (2233, 4675)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "item_users = R.T.tocsr()\n",
    "item_users.sort_indices()\n",
    "\n",
    "knn = NearestNeighbors(\n",
    "    n_neighbors=51,      # 51 cause self will be dropped later\n",
    "    metric=\"cosine\",\n",
    "    algorithm=\"brute\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "knn.fit(item_users)\n",
    "print(\"sklearn item–item fitted on\", item_users.shape)\n",
    "\n",
    "def item_neighbors_from_history_sklearn(u_seen, per_item=20):\n",
    "    C = []\n",
    "    for iid in u_seen:\n",
    "        dists, idxs = knn.kneighbors(item_users[iid], n_neighbors=per_item+1, return_distance=True)\n",
    "        neigh_ids = idxs[0][1:]   # drop self\n",
    "        C.extend(int(j) for j in neigh_ids)\n",
    "    return C\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third tool: Lightweight ALS Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 63.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from implicit.als import AlternatingLeastSquares\n",
    "\n",
    "#arbitrary ALS parameters, just need a trained model for generating pool of recs\n",
    "als = AlternatingLeastSquares(\n",
    "    factors=64,\n",
    "    regularization=0.05,\n",
    "    iterations=10,\n",
    "    use_gpu=False\n",
    ")\n",
    "\n",
    "# implicit ALS needs item×user matrix\n",
    "als.fit(R.T.tocsr())\n",
    "print(\"ALS trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rvHl_Km_UQKa"
   },
   "source": [
    "### Build candidate pools (w artifacts - popularity/item-item,als)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KrjASCypURPL",
    "outputId": "95900d54-9472-4c23-a416-bc5ae087221f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4675/4675 [09:40<00:00,  8.05it/s]\n",
      "100%|██████████| 4675/4675 [09:46<00:00,  7.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote candidates to: C:\\Users\\abdul\\OneDrive\\Documents\\GitHub\\recsysvsllms\\movielens_dataset\\candidates\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pyarrow as pa, pyarrow.parquet as pq\n",
    "\n",
    "def mf_top_unseen(uid: int, Rk):\n",
    "    ids, scores = als.recommend(\n",
    "        userid=int(uid),\n",
    "        user_items=R[int(uid)],\n",
    "        N=Rk,\n",
    "        filter_already_liked_items=True,\n",
    "        recalculate_user=True,\n",
    "    )\n",
    "    return [int(i) for i in ids]\n",
    "\n",
    "def build_pool_for_user(uid: int, # putting back parameters for easy tuning\n",
    "                        P=200,        \n",
    "                        K=400,       \n",
    "                        Rk=200,      \n",
    "                        knn_per_item=20):  \n",
    "    seen = user_seen.get(uid, set())\n",
    "    seen_set = set(seen)\n",
    "\n",
    "    C = []\n",
    "    C += top_pop_unseen(seen, P=P) #get popular unseen\n",
    "\n",
    "    if len(seen):\n",
    "        C += mf_top_unseen(uid, Rk=Rk) #ALS recs\n",
    "\n",
    "    if len(seen):\n",
    "        few = list(seen)[:12]         # only 12 items from history\n",
    "        C += item_neighbors_from_history_sklearn(few, per_item=knn_per_item)\n",
    "\n",
    "    # de-dupe movies then drop seen and limit\n",
    "    dedup = []\n",
    "    for iid in C:\n",
    "        if iid in seen_set:\n",
    "            continue\n",
    "        if iid in dedup:\n",
    "            continue\n",
    "        dedup.append(iid)\n",
    "        if len(dedup) >= K:\n",
    "            break\n",
    "\n",
    "    return dedup\n",
    "\n",
    "\n",
    "def make_candidates(user_ids, P=200, K=400, Rk=200, knn_per_item=20):\n",
    "    rows = []\n",
    "    for u in tqdm(user_ids):\n",
    "        rows.append({\n",
    "            \"uid\": int(u),\n",
    "            \"candidates\": build_pool_for_user(\n",
    "                int(u),\n",
    "                P=P,\n",
    "                K=K,\n",
    "                Rk=Rk,\n",
    "                knn_per_item=knn_per_item,\n",
    "            )\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "#build user lists\n",
    "users_val  = sorted(val_idx[\"uid\"].unique())  if len(val_idx)  else []\n",
    "users_test = sorted(test_idx[\"uid\"].unique()) if len(test_idx) else []\n",
    "\n",
    "#build pools\n",
    "cand_val  = make_candidates(users_val,  P=20,  K=50, Rk=20, knn_per_item=10) #limited it to 50 candidates for faster testing on LLMs\n",
    "cand_test = make_candidates(users_test, P=20,  K=50, Rk=20, knn_per_item=10)\n",
    "\n",
    "#finally save outputs\n",
    "OUT = SPLITS.parent / \"candidates\"\n",
    "OUT.mkdir(exist_ok=True)\n",
    "cand_val.to_parquet(OUT / \"val.parquet\", index=False)\n",
    "cand_test.to_parquet(OUT / \"test.parquet\", index=False)\n",
    "print(\"Wrote candidates to:\", OUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load & Define Covered Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ROOT = Path(\"C:/Users/abdul/OneDrive/Documents/GitHub/recsysvsllms/movielens_dataset\")\n",
    "SPLITS = ROOT / \"splits\"\n",
    "CANDS  = ROOT / \"candidates\"\n",
    "\n",
    "train_idx = pd.read_parquet(SPLITS / \"train_indexed.parquet\")   \n",
    "val_idx   = pd.read_parquet(SPLITS / \"val_targets_indexed.parquet\")\n",
    "test_idx  = pd.read_parquet(SPLITS / \"test_targets_indexed.parquet\")\n",
    "\n",
    "cand_val  = pd.read_parquet(CANDS / \"val.parquet\")  \n",
    "cand_test = pd.read_parquet(CANDS / \"test.parquet\")\n",
    "\n",
    "def coverage_rows(cands_df, targets_df, tgt_name):\n",
    "    df = cands_df.merge(\n",
    "        targets_df[[\"uid\", \"iid\"]].rename(columns={\"iid\": tgt_name}),\n",
    "        on=\"uid\", how=\"inner\"\n",
    "    )\n",
    "\n",
    "    #drop cold-start targets (iid is NaN) and rows without candidates\n",
    "    before = len(df)\n",
    "    df = df[df[tgt_name].notna() & df[\"candidates\"].notna()].copy()\n",
    "    dropped = before - len(df)\n",
    "    df[\"candidates\"] = df[\"candidates\"].apply(lambda x: list(x) if isinstance(x, (list, tuple, np.ndarray)) else [])\n",
    "\n",
    "    #using pandas for nullable Int64 to get rid of NaN issues\n",
    "    df[tgt_name] = df[tgt_name].astype(\"Int64\")\n",
    "    df[\"target_in_pool\"] = [t in set(c) for t, c in zip(df[tgt_name], df[\"candidates\"])]\n",
    "\n",
    "    print(f\"{tgt_name}: dropped {dropped} rows (cold-start/invalid); kept {len(df)}\")\n",
    "    return df\n",
    "\n",
    "val_cov  = coverage_rows(cand_val,  val_idx,  \"val_item\")\n",
    "test_cov = coverage_rows(cand_test, test_idx, \"test_item\")\n",
    "\n",
    "val_covered  = val_cov[val_cov[\"target_in_pool\"]].copy()\n",
    "test_covered = test_cov[test_cov[\"target_in_pool\"]].copy()\n",
    "\n",
    "print(f\"Coverage  val={len(val_covered)/len(val_cov):.2%}  test={len(test_covered)/len(test_cov):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get number of covered Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users valid for eval  val=432  test=404\n"
     ]
    }
   ],
   "source": [
    "def mark_coverage(cands_df: pd.DataFrame, targets_df: pd.DataFrame, tgt_name: str):\n",
    "    df = cands_df.merge(\n",
    "        targets_df[[\"uid\",\"iid\"]].rename(columns={\"iid\": tgt_name}),\n",
    "        on=\"uid\", how=\"inner\"\n",
    "    )\n",
    "    df[\"candidates\"] = df[\"candidates\"].apply(\n",
    "        lambda x: list(x) if isinstance(x, (list, tuple, np.ndarray, pd.Series)) else []\n",
    "    )\n",
    "    # fill NaNs to avoid int() on NaN\n",
    "    tgt = df[tgt_name].fillna(-1).astype(int).to_numpy()\n",
    "    df[\"target_in_pool\"] = [int(t) in set(c) for t, c in zip(tgt, df[\"candidates\"])]\n",
    "    return df[[\"uid\",\"target_in_pool\"]]\n",
    "\n",
    "val_mark  = mark_coverage(cand_val,  val_idx,  \"val_item\")\n",
    "test_mark = mark_coverage(cand_test, test_idx, \"test_item\")\n",
    "\n",
    "covered_val_uids  = set(val_mark.loc[val_mark[\"target_in_pool\"], \"uid\"])\n",
    "covered_test_uids = set(test_mark.loc[test_mark[\"target_in_pool\"], \"uid\"])\n",
    "\n",
    "print(f\"Users valid for eval  val={len(covered_val_uids)}  test={len(covered_test_uids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limit to 100 users (reused for LLMs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 100 val users\n",
      "Using 100 test users\n",
      "\n",
      "Shapes after restricting:\n",
      "  val_idx_100   : (100, 5)\n",
      "  cand_val_100  : (100, 2)\n",
      "  test_idx_100  : (100, 5)\n",
      "  cand_test_100 : (100, 2)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def new_coverage_rows(cands_df, targets_df, tgt_name):\n",
    "    df = cands_df.merge(\n",
    "        targets_df[[\"uid\", \"iid\"]].rename(columns={\"iid\": tgt_name}),\n",
    "        on=\"uid\", how=\"inner\"\n",
    "    )\n",
    "\n",
    "    before = len(df) \n",
    "    df = df[df[tgt_name].notna() & df[\"candidates\"].notna()].copy()\n",
    "    dropped = before - len(df) #dropping rows if target missing or candidates list missing\n",
    "\n",
    "    df[\"candidates\"] = df[\"candidates\"].apply( \n",
    "        lambda x: list(x) if isinstance(x, (list, tuple, np.ndarray, pd.Series)) else [] #ensuring list stype\n",
    "    )\n",
    "    df[tgt_name] = df[tgt_name].astype(\"Int64\")\n",
    "    df[\"target_in_pool\"] = [t in set(c) for t, c in zip(df[tgt_name], df[\"candidates\"])]\n",
    "\n",
    "    print(f\"{tgt_name}: dropped {dropped} rows; kept {len(df)}\")\n",
    "    return df\n",
    "\n",
    "N = 100 #setting to 100 users for LLM experiments\n",
    "\n",
    "val_uids_100  = set(list(covered_val_uids)[:N])\n",
    "test_uids_100 = set(list(covered_test_uids)[:N])\n",
    "\n",
    "print(f\"Using {len(val_uids_100)} val users\")\n",
    "print(f\"Using {len(test_uids_100)} test users\")\n",
    "\n",
    "val_idx_100   = val_idx[val_idx[\"uid\"].isin(val_uids_100)].copy() #restricting to only selected users\n",
    "test_idx_100  = test_idx[test_idx[\"uid\"].isin(test_uids_100)].copy()\n",
    "\n",
    "cand_val_100  = cand_val[cand_val[\"uid\"].isin(val_uids_100)].reset_index(drop=True)\n",
    "cand_test_100 = cand_test[cand_test[\"uid\"].isin(test_uids_100)].reset_index(drop=True)\n",
    "\n",
    "print(\"\\nShapes after restricting:\")\n",
    "print(\"  val_idx_100   :\", val_idx_100.shape)\n",
    "print(\"  cand_val_100  :\", cand_val_100.shape)\n",
    "print(\"  test_idx_100  :\", test_idx_100.shape)\n",
    "print(\"  cand_test_100 :\", cand_test_100.shape)\n",
    "\n",
    "\n",
    "#saving frozen copies for LLMs\n",
    "val_idx_100.to_parquet(SPLITS / \"val_targets_indexed_100.parquet\", index=False)\n",
    "test_idx_100.to_parquet(SPLITS / \"test_targets_indexed_100.parquet\", index=False)\n",
    "cand_val_100.to_parquet(CANDS / \"val_100.parquet\", index=False)\n",
    "cand_test_100.to_parquet(CANDS / \"test_100.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval coverage val=100.00% test=100.00%\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ROOT = Path(\"C:/Users/abdul/OneDrive/Documents/GitHub/recsysvsllms/movielens/data/dataset\")\n",
    "SPLITS = ROOT / \"splits\"\n",
    "CANDS  = ROOT / \"candidates\"\n",
    "\n",
    "train_idx = pd.read_parquet(SPLITS / \"train_indexed.parquet\")   \n",
    "\n",
    "val_eval_targets  = pd.read_parquet(SPLITS / \"val_targets_indexed_100.parquet\")\n",
    "test_eval_targets = pd.read_parquet(SPLITS / \"test_targets_indexed_100.parquet\")\n",
    "\n",
    "cand_val_eval  = pd.read_parquet(CANDS / \"val_100.parquet\")\n",
    "cand_test_eval = pd.read_parquet(CANDS / \"test_100.parquet\")\n",
    "\n",
    "# sanity check, should print 100%\n",
    "def coverage_percent(cands_df, targets_df, tgt_col):\n",
    "    df = cands_df.merge(targets_df[[\"uid\", tgt_col]], on=\"uid\")\n",
    "    return np.mean([int(t) in set(c) for t, c in zip(df[tgt_col], df[\"candidates\"])])\n",
    "\n",
    "print(\"Eval coverage\",\n",
    "      f\"val={coverage_percent(cand_val_eval,  val_eval_targets,  'iid'):.2%}\",\n",
    "      f\"test={coverage_percent(cand_test_eval, test_eval_targets, 'iid'):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Recommender System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:03<00:00, 55.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS training time: 3.62 seconds\n",
      "ALS shapes  user_factors: (4675, 96)  item_factors: (2233, 96)  U: 4675  I: 2233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.nearest_neighbours import bm25_weight, tfidf_weight \n",
    "import time  \n",
    "\n",
    "U = int(train_idx[\"uid\"].max()) + 1 #building users × items CSR from train_idx \n",
    "I = int(train_idx[\"iid\"].max()) + 1\n",
    "\n",
    "rows = train_idx[\"uid\"].to_numpy(dtype=np.int32, copy=False)\n",
    "cols = train_idx[\"iid\"].to_numpy(dtype=np.int32, copy=False)\n",
    "data = np.ones(len(train_idx), dtype=np.float32)\n",
    "\n",
    "alpha = 15\n",
    "R = csr_matrix((data, (rows, cols)), shape=(U, I), dtype=np.float32)\n",
    "X = bm25_weight(R, K1=100, B=0.8).astype(np.float32)\n",
    "\n",
    "als = AlternatingLeastSquares( #training ALS\n",
    "    factors=96,\n",
    "    regularization=0.05,\n",
    "    iterations=200,\n",
    "    use_gpu=False,     \n",
    "    dtype=np.float32,\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "als.fit(alpha*X)\n",
    "end = time.time()\n",
    "print(f\"ALS training time: {end - start:.2f} seconds\")\n",
    "\n",
    "U_f = als.user_factors   # get shapes/embeddings\n",
    "V_f = als.item_factors   \n",
    "\n",
    "print(\"ALS shapes  user_factors:\", U_f.shape, \" item_factors:\", V_f.shape, \" U:\", U, \" I:\", I)\n",
    "assert U_f.shape[0] == U and V_f.shape[0] == I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sparsity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users: 4675, Items: 2233, Interactions: 12557\n",
      "Sparsity: 0.998797\n"
     ]
    }
   ],
   "source": [
    "num_users = U\n",
    "num_items = I\n",
    "num_interactions = len(train_idx)\n",
    "sparsity = 1 - (num_interactions / (num_users * num_items))\n",
    "print(f\"Users: {num_users}, Items: {num_items}, Interactions: {num_interactions}\")\n",
    "print(f\"Sparsity: {sparsity:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL]  ALS HR@5=0.190 NDCG@5=0.117 HR@10=0.300 NDCG@10=0.155 HR@20=0.440 NDCG@20=0.189\n",
      "[TEST] ALS HR@5=0.070 NDCG@5=0.051 HR@10=0.260 NDCG@10=0.067 HR@20=0.350 NDCG@20=0.124\n"
     ]
    }
   ],
   "source": [
    "#need to first join targets with candidate pools\n",
    "val_eval  = (cand_val_eval\n",
    "             .merge(val_eval_targets[[\"uid\",\"iid\"]]\n",
    "                    .rename(columns={\"iid\":\"target\"}), on=\"uid\"))\n",
    "test_eval = (cand_test_eval\n",
    "             .merge(test_eval_targets[[\"uid\",\"iid\"]]\n",
    "                    .rename(columns={\"iid\":\"target\"}), on=\"uid\"))\n",
    "\n",
    "I   = V_f.shape[0] # setting I to number of items\n",
    "\n",
    "def score_als(uid: int, cand_iids: list[int]) -> np.ndarray:\n",
    "    if not cand_iids:\n",
    "        return np.asarray([])\n",
    "    u = U_f[int(uid)]\n",
    "    c = np.array([int(i) for i in cand_iids if 0 <= int(i) < I], dtype=np.int64)\n",
    "    if c.size == 0:\n",
    "        return np.asarray([])\n",
    "    return V_f[c] @ u\n",
    "\n",
    "def hit_at_k(ranked, tgt, k):\n",
    "    return 1.0 if tgt in ranked[:k] else 0.0\n",
    "\n",
    "def ndcg_at_k(ranked, tgt, k):\n",
    "    for rank, iid in enumerate(ranked[:k], start=1):\n",
    "        if iid == tgt:\n",
    "            return 1.0 / np.log2(rank + 1)  # +1 in denom because ranks start at 1\n",
    "    return 0.0\n",
    "\n",
    "def eval_pool(df_eval: pd.DataFrame, scorer, ks=[5, 10, 20]):\n",
    "    results = {f\"hr@{k}\": [] for k in ks}\n",
    "    results.update({f\"ndcg@{k}\": [] for k in ks})\n",
    "    for _, r in df_eval.iterrows():\n",
    "        uid  = int(r[\"uid\"])\n",
    "        cnds = [int(x) for x in (r[\"candidates\"] if isinstance(r[\"candidates\"], (list, tuple, np.ndarray, pd.Series)) else [])]\n",
    "        tgt  = int(r[\"target\"])\n",
    "        if not cnds:\n",
    "            continue\n",
    "        scores = scorer(uid, cnds)\n",
    "        if scores.size == 0:\n",
    "            continue\n",
    "        order  = np.argsort(-scores)\n",
    "        ranked = [cnds[i] for i in order]\n",
    "        for k in ks:\n",
    "            results[f\"hr@{k}\"].append(hit_at_k(ranked, tgt, k))\n",
    "            results[f\"ndcg@{k}\"].append(ndcg_at_k(ranked, tgt, k))\n",
    "    return {key: float(np.mean(val)) for key, val in results.items()}\n",
    "\n",
    "ks = [5, 10, 20]\n",
    "val_metrics = eval_pool(val_eval, score_als, ks=ks)\n",
    "test_metrics = eval_pool(test_eval, score_als, ks=ks)\n",
    "\n",
    "print(\"[VAL]  ALS\", \" \".join([f\"HR@{k}={val_metrics[f'hr@{k}']:.3f} NDCG@{k}={val_metrics[f'ndcg@{k}']:.3f}\" for k in ks]))\n",
    "print(\"[TEST] ALS\", \" \".join([f\"HR@{k}={test_metrics[f'hr@{k}']:.3f} NDCG@{k}={test_metrics[f'ndcg@{k}']:.3f}\" for k in ks]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\abdul\\.venvs\\ece1508gp\\lib\\site-packages\\implicit\\utils.py:164: ParameterWarning: Method expects CSR input, and was passed coo_matrix instead. Converting to CSR took 0.0010013580322265625 seconds \n",
      "  warnings.warn(\n",
      "100%|██████████| 150/150 [00:03<00:00, 45.56it/s]\n",
      "c:\\Users\\abdul\\.venvs\\ece1508gp\\lib\\site-packages\\implicit\\utils.py:164: ParameterWarning: Method expects CSR input, and was passed coo_matrix instead. Converting to CSR took 0.0009970664978027344 seconds\n",
      "  warnings.warn(\n",
      "100%|██████████| 150/150 [00:03<00:00, 46.62it/s]\n",
      "100%|██████████| 150/150 [00:03<00:00, 42.96it/s]\n",
      "c:\\Users\\abdul\\.venvs\\ece1508gp\\lib\\site-packages\\implicit\\utils.py:164: ParameterWarning: Method expects CSR input, and was passed coo_matrix instead. Converting to CSR took 0.000997781753540039 seconds\n",
      "  warnings.warn(\n",
      "100%|██████████| 200/200 [00:04<00:00, 42.02it/s]\n",
      "100%|██████████| 200/200 [00:04<00:00, 41.79it/s]\n",
      "100%|██████████| 200/200 [00:05<00:00, 37.13it/s]\n",
      "100%|██████████| 200/200 [00:06<00:00, 30.87it/s]\n",
      "c:\\Users\\abdul\\.venvs\\ece1508gp\\lib\\site-packages\\implicit\\utils.py:164: ParameterWarning: Method expects CSR input, and was passed coo_matrix instead. Converting to CSR took 0.0010073184967041016 seconds\n",
      "  warnings.warn(\n",
      "100%|██████████| 200/200 [00:05<00:00, 33.85it/s]\n",
      "c:\\Users\\abdul\\.venvs\\ece1508gp\\lib\\site-packages\\implicit\\utils.py:164: ParameterWarning: Method expects CSR input, and was passed coo_matrix instead. Converting to CSR took 0.0020036697387695312 seconds\n",
      "  warnings.warn(\n",
      "100%|██████████| 200/200 [00:05<00:00, 38.54it/s]\n",
      "100%|██████████| 200/200 [00:05<00:00, 39.25it/s]\n",
      "100%|██████████| 200/200 [00:04<00:00, 41.93it/s]\n",
      "100%|██████████| 200/200 [00:05<00:00, 38.35it/s]\n",
      "   factors   reg  alpha  iters    val_HR  val_NDCG   test_HR  test_NDCG\n",
      "0       64  0.05     15    150  0.366667  0.201420  0.260000   0.131664\n",
      "1       96  0.05     15    200  0.303333  0.151813  0.240000   0.117803\n",
      "3      128  0.05     20    200  0.293333  0.141607  0.186667   0.092527\n",
      "2      128  0.10     10    200  0.296667  0.137689  0.180000   0.094043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def ndcg_at_k(ranked, tgt, k=10):\n",
    "    for rank, iid in enumerate(ranked[:k], start=1):\n",
    "        if iid == tgt:\n",
    "            return 1.0 / np.log2(rank + 1)\n",
    "    return 0.0\n",
    "\n",
    "def hit_at_k(ranked, tgt, k=10):\n",
    "    return 1.0 if tgt in ranked[:k] else 0.0\n",
    "\n",
    "def eval_pool(df_eval, scorer, k=10):\n",
    "    hits, ndcgs = [], []\n",
    "    for _, r in df_eval.iterrows():\n",
    "        uid  = int(r[\"uid\"])\n",
    "        cnds = r[\"candidates\"]\n",
    "        if not isinstance(cnds, (list, tuple, np.ndarray, pd.Series)) or len(cnds) == 0:\n",
    "            continue\n",
    "        cnds = [int(x) for x in cnds]\n",
    "        scores = scorer(uid, cnds)\n",
    "        if scores.size == 0:\n",
    "            continue\n",
    "        order  = np.argsort(-scores)\n",
    "        ranked = [cnds[i] for i in order]\n",
    "        hits.append(hit_at_k(ranked, int(r[\"target\"]), k))\n",
    "        ndcgs.append(ndcg_at_k(ranked, int(r[\"target\"]), k))\n",
    "    return float(np.mean(hits)), float(np.mean(ndcgs))\n",
    "\n",
    "def train_eval_als_once(seed, R, alpha, factors, reg, iters, use_gpu,\n",
    "                        val_eval, test_eval, k=10):\n",
    "    X = bm25_weight(R, K1=100, B=0.8).astype(np.float32)\n",
    "    als = AlternatingLeastSquares(\n",
    "        factors=factors,\n",
    "        regularization=reg,\n",
    "        iterations=iters,\n",
    "        use_gpu=use_gpu,\n",
    "        dtype=np.float32,\n",
    "        random_state=seed,\n",
    "    )\n",
    "    als.fit(alpha * X)\n",
    "\n",
    "    U_f = als.user_factors\n",
    "    V_f = als.item_factors\n",
    "    I   = V_f.shape[0]\n",
    "\n",
    "    def score_als(uid, cand_iids):\n",
    "        if not cand_iids: return np.asarray([])\n",
    "        u = U_f[int(uid)]\n",
    "        c = np.array([int(i) for i in cand_iids if 0 <= int(i) < I], dtype=np.int64)\n",
    "        if c.size == 0: return np.asarray([])\n",
    "        return V_f[c] @ u\n",
    "\n",
    "    return eval_pool(val_eval,  score_als, k), eval_pool(test_eval, score_als, k)\n",
    "\n",
    "param_grid = [ #grid search for hyperparam tuning\n",
    "    {\"factors\": 64,  \"reg\": 0.05, \"alpha\": 15, \"iters\": 150},\n",
    "    {\"factors\": 96,  \"reg\": 0.05, \"alpha\": 15, \"iters\": 200},\n",
    "    {\"factors\": 128, \"reg\": 0.1,  \"alpha\": 10, \"iters\": 200},\n",
    "    {\"factors\": 128, \"reg\": 0.05, \"alpha\": 20, \"iters\": 200},\n",
    "]\n",
    "\n",
    "results = []\n",
    "seeds = [0, 1, 2]  # average across a few random seeds\n",
    "\n",
    "for params in param_grid:\n",
    "    vals, tests = [], []\n",
    "    for s in seeds:\n",
    "        val_metrics, test_metrics = train_eval_als_once(\n",
    "            seed=s,\n",
    "            R=R,\n",
    "            alpha=params[\"alpha\"],\n",
    "            factors=params[\"factors\"],\n",
    "            reg=params[\"reg\"],\n",
    "            iters=params[\"iters\"],\n",
    "            use_gpu=False,\n",
    "            val_eval=val_eval,\n",
    "            test_eval=test_eval,\n",
    "            k=10,\n",
    "        )\n",
    "        vals.append(val_metrics)\n",
    "        tests.append(test_metrics)\n",
    "\n",
    "    vals, tests = np.array(vals), np.array(tests)\n",
    "    val_mean, val_std = vals.mean(0), vals.std(0)\n",
    "    test_mean, test_std = tests.mean(0), tests.std(0)\n",
    "\n",
    "    results.append({\n",
    "        **params,\n",
    "        \"val_HR\": val_mean[0], \"val_NDCG\": val_mean[1],\n",
    "        \"test_HR\": test_mean[0], \"test_NDCG\": test_mean[1],\n",
    "    })\n",
    "\n",
    "res_df = pd.DataFrame(results)\n",
    "print(res_df.sort_values(\"val_NDCG\", ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best ALS hyperparameters: factors=64, regularization=0.05, alpha=15, iterations=150"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMhHE0NBlH/BSXrGjJvquND",
   "include_colab_link": true,
   "mount_file_id": "1v14zduS8ZnCfMpMoMMIvkrRdQZqD7Ei0",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ece1508gp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
