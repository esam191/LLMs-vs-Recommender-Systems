{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fde3b9f7186896c",
   "metadata": {},
   "source": [
    "# Amazon Books – Data Preprocessing and Baseline\n",
    "\n",
    "This notebook prepares the Amazon Books dataset for our project:\n",
    "\n",
    "1. Normalize and filter the raw Amazon ratings.\n",
    "2. Create a time-aware leave-one-out (LOO) split.\n",
    "3. Build candidate pools and a 100-user subset shared with the LLMs.\n",
    "4. Truncate training histories to a fixed length.\n",
    "5. Export splits and candidates to CSV.\n",
    "6. Build and clean item-level metadata (title + merged review description).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2604e1cb01ff854",
   "metadata": {},
   "source": [
    "## 0. Reset local output folders\n",
    "\n",
    "This cell removes any previous outputs (`splits/`, `candidates_subset100/`, `csv_export/`) so the notebook can be re-run from scratch without leftover files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T03:45:14.115464Z",
     "start_time": "2025-11-28T03:45:14.091283Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[clean] removed C:\\Users\\carlk\\OneDrive\\Documents\\uoft\\ECE1508H F\\Project\\splits\n",
      "[clean] removed C:\\Users\\carlk\\OneDrive\\Documents\\uoft\\ECE1508H F\\Project\\candidates_subset100\n",
      "[clean] removed C:\\Users\\carlk\\OneDrive\\Documents\\uoft\\ECE1508H F\\Project\\csv_export\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(r\"C:\\Users\\carlk\\OneDrive\\Documents\\uoft\\ECE1508H F\\Project\")\n",
    "\n",
    "folders_to_clean = [\n",
    "    \"splits\",\n",
    "    \"candidates_subset100\",\n",
    "    \"csv_export\"\n",
    "]\n",
    "\n",
    "for d in folders_to_clean:\n",
    "    p = BASE / d\n",
    "    if p.exists():\n",
    "        shutil.rmtree(p)\n",
    "        print(\"[clean] removed\", p)\n",
    "    else:\n",
    "        print(\"[clean] not found\", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62d9972e3a1974f",
   "metadata": {},
   "source": [
    "## 1. Load and normalize raw Amazon Books ratings\n",
    "\n",
    "I start from the `Books_rating.csv` file (Kaggle-style export), rename columns to `userId`, `itemId`, `rating`, `timestamp`, and keep only ratings in \\[1, 5].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f1e456a8558257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "CSV_PATH = BASE / \"Books_rating.csv\"\n",
    "assert CSV_PATH.exists(), f\"Missing file: {CSV_PATH}\"\n",
    "\n",
    "df_raw = pd.read_csv(CSV_PATH)\n",
    "print(\"Raw columns:\", list(df_raw.columns))\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"userId\":    df_raw[\"User_id\"],\n",
    "    \"itemId\":    df_raw[\"Id\"],\n",
    "    \"rating\":    pd.to_numeric(df_raw[\"review/score\"], errors=\"coerce\"),\n",
    "    \"timestamp\": pd.to_datetime(df_raw[\"review/time\"], errors=\"coerce\"),\n",
    "})\n",
    "\n",
    "df[\"timestamp\"] = df[\"timestamp\"].fillna(pd.Timestamp(2000,1,1))\n",
    "df[\"timestamp\"] = (df[\"timestamp\"].astype(\"int64\") // 10**9)\n",
    "\n",
    "df = df[(df[\"rating\"] >= 1) & (df[\"rating\"] <= 5)]\n",
    "\n",
    "print(df.head(), df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3692dec09e04ed3d",
   "metadata": {},
   "source": [
    "### 1.1 Apply k-core filter\n",
    "\n",
    "I apply a user–item k-core filter so that every user and item has at least 5 positive interactions. This stabilizes the recommendation baseline and makes the split comparable to MovieLens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5bf3e0d8ca57d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw columns: ['Id', 'Title', 'Price', 'User_id', 'profileName', 'review/helpfulness', 'review/score', 'review/time', 'review/summary', 'review/text']\n",
      "           userId      itemId  rating  timestamp\n",
      "0   AVCGYZL8FQQTD  1882931173     4.0          0\n",
      "1  A30TK6U7DNS82R  0826414346     5.0          1\n",
      "2  A3UH4UZ4RSVO82  0826414346     5.0          1\n",
      "3  A2MVUWT453QH61  0826414346     4.0          1\n",
      "4  A22X4XUPKF66MR  0826414346     4.0          1 userId        object\n",
      "itemId        object\n",
      "rating       float64\n",
      "timestamp      int64\n",
      "dtype: object\n",
      "[k-core 1] rows 3,000,000->1,077,091, users 1,008,972->82,519, items 221,998->69,986\n",
      "[k-core 2] rows 1,077,091->977,301, users 82,519->77,225, items 69,986->29,668\n",
      "[k-core 3] rows 977,301->951,522, users 77,225->70,381, items 29,668->28,742\n",
      "[k-core 4] rows 951,522->944,212, users 70,381->70,121, items 28,742->27,027\n",
      "[k-core 5] rows 944,212->941,724, users 70,121->69,534, items 27,027->26,952\n",
      "[k-core 6] rows 941,724->940,863, users 69,534->69,496, items 26,952->26,770\n",
      "[k-core 7] rows 940,863->940,525, users 69,496->69,417, items 26,770->26,757\n",
      "[k-core 8] rows 940,525->940,434, users 69,417->69,416, items 26,757->26,731\n",
      "[k-core 9] rows 940,434->940,416, users 69,416->69,411, items 26,731->26,731\n",
      "[k-core 10] rows 940,416->940,416, users 69,411->69,411, items 26,731->26,731\n",
      "[after k-core] users=69,411, items=26,731, rows=940,416\n",
      "[saved] C:\\Users\\carlk\\OneDrive\\Documents\\uoft\\ECE1508H F\\Project\\ratings.csv ~ 940,416 rows\n"
     ]
    }
   ],
   "source": [
    "def kcore_filter(df, u_col=\"userId\", i_col=\"itemId\", k_user=5, k_item=5, max_iters=20, verbose=True):\n",
    "    for it in range(max_iters):\n",
    "        n0, u0, i0 = len(df), df[u_col].nunique(), df[i_col].nunique()\n",
    "        uf = df[u_col].value_counts()\n",
    "        vf = df[i_col].value_counts()\n",
    "        df = df[df[u_col].isin(uf[uf >= k_user].index)]\n",
    "        df = df[df[i_col].isin(vf[vf >= k_item].index)]\n",
    "        n1, u1, i1 = len(df), df[u_col].nunique(), df[i_col].nunique()\n",
    "        if verbose:\n",
    "            print(f\"[k-core {it+1}] rows {n0:,}->{n1:,}, users {u0:,}->{u1:,}, items {i0:,}->{i1:,}\")\n",
    "        if n1 == n0:\n",
    "            break\n",
    "    return df\n",
    "\n",
    "df = kcore_filter(df, k_user=5, k_item=5)\n",
    "print(f\"[after k-core] users={df['userId'].nunique():,}, items={df['itemId'].nunique():,}, rows={len(df):,}\")\n",
    "\n",
    "ratings_csv = BASE / \"ratings.csv\"\n",
    "df.to_csv(ratings_csv, index=False)\n",
    "print(f\"[saved] {ratings_csv} ~ {len(df):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e14a172ead2843a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T03:46:23.743057Z",
     "start_time": "2025-11-28T03:46:23.720823Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_aware_loo_split(\n",
    "    ratings_csv: str,\n",
    "    out_dir: str,\n",
    "    rating_threshold: float = 4.0,\n",
    "    min_positives: int = 2,\n",
    "    also_csv: bool = False,\n",
    "):\n",
    "    out = Path(out_dir); (out / \"splits\").mkdir(parents=True, exist_ok=True)\n",
    "    ratings = pd.read_csv(ratings_csv)\n",
    "\n",
    "    need = {\"userId\",\"itemId\",\"rating\",\"timestamp\"}\n",
    "    missing = need - set(ratings.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"ratings.csv missing columns: {missing}\")\n",
    "\n",
    "    unit = \"ms\" if float(ratings[\"timestamp\"].max()) > 1e12 else \"s\"\n",
    "    ratings[\"ts\"] = pd.to_datetime(ratings[\"timestamp\"], unit=unit)\n",
    "\n",
    "    pos = ratings[ratings[\"rating\"] >= rating_threshold].copy()\n",
    "\n",
    "    pos = pos.drop_duplicates([\"userId\",\"itemId\"], keep=\"first\")\n",
    "\n",
    "    cnt = pos.groupby(\"userId\")[\"itemId\"].transform(\"size\")\n",
    "    pos = pos[cnt >= min_positives].copy()\n",
    "\n",
    "    pos = pos.sort_values([\"userId\",\"ts\"], kind=\"mergesort\")\n",
    "    pos[\"n\"]   = pos.groupby(\"userId\")[\"userId\"].transform(\"size\")\n",
    "    pos[\"idx\"] = pos.groupby(\"userId\").cumcount()\n",
    "    pos[\"split\"] = \"train\"\n",
    "    pos.loc[pos[\"idx\"] == pos[\"n\"]-1, \"split\"] = \"test\"\n",
    "    pos.loc[(pos[\"n\"] >= 3) & (pos[\"idx\"] == pos[\"n\"]-2), \"split\"] = \"val\"\n",
    "\n",
    "    train = pos[pos[\"split\"]==\"train\"][[\"userId\",\"itemId\",\"ts\"]].reset_index(drop=True)\n",
    "    val_targets  = (pos[pos[\"split\"]==\"val\"][[\"userId\",\"itemId\",\"ts\"]]\n",
    "                    .rename(columns={\"itemId\":\"val_item\",\"ts\":\"ts_val\"}).reset_index(drop=True))\n",
    "    test_targets = (pos[pos[\"split\"]==\"test\"][[\"userId\",\"itemId\",\"ts\"]]\n",
    "                    .rename(columns={\"itemId\":\"test_item\",\"ts\":\"ts_test\"}).reset_index(drop=True))\n",
    "\n",
    "    uids = pd.DataFrame(sorted(train[\"userId\"].unique()), columns=[\"userId\"]); uids[\"uid\"] = range(len(uids))\n",
    "    iids = pd.DataFrame(sorted(train[\"itemId\"].unique()), columns=[\"itemId\"]); iids[\"iid\"] = range(len(iids))\n",
    "\n",
    "    val_idx  = (val_targets.merge(uids, on=\"userId\", how=\"inner\")\n",
    "                          .merge(iids, left_on=\"val_item\", right_on=\"itemId\", how=\"left\")\n",
    "                          .drop(columns=[\"itemId\"]))\n",
    "    test_idx = (test_targets.merge(uids, on=\"userId\", how=\"inner\")\n",
    "                          .merge(iids, left_on=\"test_item\", right_on=\"itemId\", how=\"left\")\n",
    "                          .drop(columns=[\"itemId\"]))\n",
    "\n",
    "    sp = out / \"splits\"\n",
    "    train.to_parquet(sp / \"train.parquet\", index=False)\n",
    "    if len(val_targets):  val_targets.to_parquet(sp / \"val_targets.parquet\", index=False)\n",
    "    test_targets.to_parquet(sp / \"test_targets.parquet\", index=False)\n",
    "    uids.to_parquet(sp / \"user_id_map.parquet\", index=False)\n",
    "    iids.to_parquet(sp / \"item_id_map.parquet\", index=False)\n",
    "    (train.merge(uids, on=\"userId\", how=\"inner\")\n",
    "          .merge(iids, on=\"itemId\", how=\"inner\")\n",
    "          .drop(columns=[\"userId\",\"itemId\"])\n",
    "          .to_parquet(sp / \"train_indexed.parquet\", index=False))\n",
    "    if len(val_idx):   val_idx.to_parquet(sp / \"val_targets_indexed.parquet\", index=False)\n",
    "    test_idx.to_parquet(sp / \"test_targets_indexed.parquet\", index=False)\n",
    "\n",
    "    cold_val  = int(val_idx[\"iid\"].isna().sum()) if len(val_idx) else 0\n",
    "    cold_test = int(test_idx[\"iid\"].isna().sum()) if \"iid\" in test_idx else 0\n",
    "    stats = f\"\"\"Time-aware LOO split summary\n",
    "Users (TRAIN map): {len(uids):,}\n",
    "Items (TRAIN map): {len(iids):,}\n",
    "TRAIN positives : {len(train):,}\n",
    "VAL users       : {val_idx[\"uid\"].nunique() if len(val_idx) else 0:,}\n",
    "TEST users      : {test_idx[\"uid\"].nunique() if len(test_idx) else 0:,}\n",
    "Cold-start VAL items : {cold_val}\n",
    "Cold-start TEST items: {cold_test}\n",
    "\"\"\"\n",
    "    (sp / \"stats.txt\").write_text(stats, encoding=\"utf-8\")\n",
    "    print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c68c091e1012fc",
   "metadata": {},
   "source": [
    "## 2. Create time-aware leave-one-out (LOO) split\n",
    "\n",
    "I convert timestamps to a consistent unit and create a time-aware leave-one-out split:\n",
    "\n",
    "1. Keep only ratings ≥ 3.0 as positives.\n",
    "2. Require at least 5 positives per user.\n",
    "3. For each user, use the most recent item as test, the second most recent as validation, and the rest as train.\n",
    "\n",
    "The outputs are written to `splits/` as Parquet files (`train.parquet`, `val_targets.parquet`, `test_targets.parquet`, plus `user_id_map` and `item_id_map`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8319054b873fdc3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T03:46:30.101494Z",
     "start_time": "2025-11-28T03:46:23.756042Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-aware LOO split summary\n",
      "Users (TRAIN map): 60597\n",
      "Items (TRAIN map): 26522\n",
      "TRAIN positives : 690814\n",
      "VAL users       : 60597\n",
      "TEST users      : 60597\n",
      "Cold-start VAL items : 228\n",
      "Cold-start TEST items: 994\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def _detect_ts_unit(ts_series: pd.Series) -> str:\n",
    "    vmax = float(ts_series.max())\n",
    "    return \"ms\" if vmax > 1e12 else \"s\"\n",
    "\n",
    "def time_aware_loo_split(\n",
    "    ratings_csv: str,\n",
    "    out_dir: str,\n",
    "    rating_threshold: float = 3.0,\n",
    "    min_positives: int = 3,\n",
    "    also_csv: bool = False,\n",
    "):\n",
    "    out = Path(out_dir); (out / \"splits\").mkdir(parents=True, exist_ok=True)\n",
    "    ratings = pd.read_csv(ratings_csv)\n",
    "\n",
    "    need = {\"userId\",\"itemId\",\"rating\",\"timestamp\"}\n",
    "    missing = need - set(ratings.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"ratings.csv missing columns: {missing}\")\n",
    "\n",
    "\n",
    "    try:\n",
    "        unit = _detect_ts_unit(ratings[\"timestamp\"])\n",
    "        ratings[\"ts\"] = pd.to_datetime(ratings[\"timestamp\"], unit=unit)\n",
    "    except Exception:\n",
    "\n",
    "        ratings[\"ts\"] = pd.to_datetime(ratings[\"timestamp\"], unit=\"s\", origin=\"unix\", errors=\"ignore\")\n",
    "\n",
    "    pos = ratings[ratings[\"rating\"] >= rating_threshold].copy()\n",
    "    pos = pos.sort_values([\"userId\",\"itemId\",\"ts\"], kind=\"mergesort\").drop_duplicates([\"userId\",\"itemId\"], keep=\"first\")\n",
    "    pos = pos.groupby(\"userId\").filter(lambda g: len(g) >= min_positives)\n",
    "\n",
    "    pos = pos.sort_values([\"userId\",\"ts\"], kind=\"mergesort\")\n",
    "    pos[\"n\"]   = pos.groupby(\"userId\")[\"itemId\"].transform(\"size\")\n",
    "    pos[\"idx\"] = pos.groupby(\"userId\").cumcount()\n",
    "\n",
    "    pos[\"split\"] = \"train\"\n",
    "    pos.loc[pos[\"idx\"]==pos[\"n\"]-1, \"split\"] = \"test\"\n",
    "    pos.loc[(pos[\"n\"]>=3) & (pos[\"idx\"]==pos[\"n\"]-2), \"split\"] = \"val\"\n",
    "\n",
    "    train = pos[pos[\"split\"]==\"train\"][[\"userId\",\"itemId\",\"ts\"]].reset_index(drop=True)\n",
    "    val_targets  = pos[pos[\"split\"]==\"val\"][[\"userId\",\"itemId\",\"ts\"]].rename(columns={\"itemId\":\"val_item\",\"ts\":\"ts_val\"}).reset_index(drop=True)\n",
    "    test_targets = pos[pos[\"split\"]==\"test\"][[\"userId\",\"itemId\",\"ts\"]].rename(columns={\"itemId\":\"test_item\",\"ts\":\"ts_test\"}).reset_index(drop=True)\n",
    "\n",
    "    uids = pd.DataFrame(sorted(train[\"userId\"].unique()), columns=[\"userId\"]); uids[\"uid\"]=range(len(uids))\n",
    "    iids = pd.DataFrame(sorted(train[\"itemId\"].unique()), columns=[\"itemId\"]); iids[\"iid\"]=range(len(iids))\n",
    "\n",
    "    train_idx = (train.merge(uids, on=\"userId\").merge(iids, on=\"itemId\"))\n",
    "    val_idx   = (val_targets.merge(uids, on=\"userId\", how=\"inner\")\n",
    "                           .merge(iids, left_on=\"val_item\", right_on=\"itemId\", how=\"left\")\n",
    "                           .drop(columns=[\"itemId\"]))\n",
    "    test_idx  = (test_targets.merge(uids, on=\"userId\", how=\"inner\")\n",
    "                             .merge(iids, left_on=\"test_item\", right_on=\"itemId\", how=\"left\")\n",
    "                             .drop(columns=[\"itemId\"]))\n",
    "\n",
    "    sp = Path(out_dir) / \"splits\"\n",
    "    train.to_parquet(sp/\"train.parquet\", index=False)\n",
    "    val_targets.to_parquet(sp/\"val_targets.parquet\", index=False)\n",
    "    test_targets.to_parquet(sp/\"test_targets.parquet\", index=False)\n",
    "    uids.to_parquet(sp/\"user_id_map.parquet\", index=False)\n",
    "    iids.to_parquet(sp/\"item_id_map.parquet\", index=False)\n",
    "    train_idx.to_parquet(sp/\"train_indexed.parquet\", index=False)\n",
    "    val_idx.to_parquet(sp/\"val_targets_indexed.parquet\", index=False)\n",
    "    test_idx.to_parquet(sp/\"test_targets_indexed.parquet\", index=False)\n",
    "\n",
    "    if also_csv:\n",
    "        for p in [\"train\",\"val_targets\",\"test_targets\",\"user_id_map\",\"item_id_map\",\"train_indexed\",\"val_targets_indexed\",\"test_targets_indexed\"]:\n",
    "            pd.read_parquet(sp/f\"{p}.parquet\").to_csv(sp/f\"{p}.csv\", index=False)\n",
    "\n",
    "    cold_val  = int(val_idx[\"iid\"].isna().sum()) if \"iid\" in val_idx.columns else 0\n",
    "    cold_test = int(test_idx[\"iid\"].isna().sum()) if \"iid\" in test_idx.columns else 0\n",
    "    stats = f\"\"\"Time-aware LOO split summary\n",
    "Users (TRAIN map): {len(uids)}\n",
    "Items (TRAIN map): {len(iids)}\n",
    "TRAIN positives : {len(train)}\n",
    "VAL users       : {len(val_targets['userId'].unique())}\n",
    "TEST users      : {len(test_targets['userId'].unique())}\n",
    "Cold-start VAL items : {cold_val}\n",
    "Cold-start TEST items: {cold_test}\n",
    "\"\"\"\n",
    "    (sp/\"stats.txt\").write_text(stats, encoding=\"utf-8\")\n",
    "    print(stats)\n",
    "\n",
    "# Run split on the normalized Kaggle CSV\n",
    "time_aware_loo_split(\n",
    "    ratings_csv=str(BASE/\"ratings.csv\"),\n",
    "    out_dir=str(BASE),\n",
    "    rating_threshold=3.0,\n",
    "    min_positives=5,\n",
    "    also_csv=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5458cf22cb944ff6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T03:46:30.711495Z",
     "start_time": "2025-11-28T03:46:30.109868Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[covered] kept val: 60369  / test: 59603\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "SPLITS = BASE / \"splits\"\n",
    "train_idx = pd.read_parquet(SPLITS/\"train_indexed.parquet\")\n",
    "val_idx   = pd.read_parquet(SPLITS/\"val_targets_indexed.parquet\")\n",
    "test_idx  = pd.read_parquet(SPLITS/\"test_targets_indexed.parquet\")\n",
    "\n",
    "train_items = set(train_idx[\"iid\"].unique())\n",
    "val_keep  = val_idx[val_idx[\"iid\"].isin(train_items)].copy()\n",
    "test_keep = test_idx[test_idx[\"iid\"].isin(train_items)].copy()\n",
    "\n",
    "val_keep.to_parquet(SPLITS/\"val_targets_indexed.parquet\", index=False)\n",
    "test_keep.to_parquet(SPLITS/\"test_targets_indexed.parquet\", index=False)\n",
    "print(\"[covered] kept val:\", len(val_keep), \" / test:\", len(test_keep))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbe91c78f7083c0",
   "metadata": {},
   "source": [
    "## 3. Build implicit feedback matrix and item–item baseline\n",
    "\n",
    "Here I:\n",
    "\n",
    "1. Load the indexed train / val / test splits from `splits/`.\n",
    "2. Build an implicit user–item matrix `R` from the last 200 interactions per user.\n",
    "3. Compute an item–item similarity map (`item_sim_map`) using cosine similarity.\n",
    "4. Use this to construct a popularity + item-sim candidate pool for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea1dd888e565b82f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T03:46:32.870456Z",
     "start_time": "2025-11-28T03:46:30.719231Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "SPLITS = BASE / \"splits\"\n",
    "train_idx = pd.read_parquet(SPLITS/\"train_indexed.parquet\")   # [uid, iid, ts]\n",
    "val_idx   = pd.read_parquet(SPLITS/\"val_targets_indexed.parquet\")   # [uid, val_item(iid), ts_val]\n",
    "test_idx  = pd.read_parquet(SPLITS/\"test_targets_indexed.parquet\")  # [uid, test_item(iid), ts_test]\n",
    "\n",
    "U = int(train_idx[\"uid\"].max()) + 1\n",
    "I = int(train_idx[\"iid\"].max()) + 1\n",
    "\n",
    "user_seen = train_idx.groupby(\"uid\")[\"iid\"].apply(set).to_dict()\n",
    "\n",
    "def candidate_coverage(cand_df, targets_df, tgt_col=\"iid\"):\n",
    "    df = cand_df.merge(targets_df[[\"uid\", tgt_col]], on=\"uid\", how=\"inner\")\n",
    "    df = df[df[tgt_col].notna()]\n",
    "    return np.mean([(int(t) in set(c)) for t, c in zip(df[tgt_col], df[\"candidates\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "139b02f64124c0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T03:46:34.725149Z",
     "start_time": "2025-11-28T03:46:32.878171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[item-sim] built for I=26,522. Example of item 0: [22817, 8, 8128, 20791, 486, 14817, 22719, 22573, 13328, 4209]\n"
     ]
    }
   ],
   "source": [
    "train_idx_sorted = train_idx.sort_values([\"uid\",\"ts\"]).groupby(\"uid\").tail(200)\n",
    "\n",
    "R = csr_matrix(\n",
    "    (np.ones(len(train_idx_sorted), dtype=np.float32),\n",
    "     (train_idx_sorted[\"uid\"].astype(int).values,\n",
    "      train_idx_sorted[\"iid\"].astype(int).values)),\n",
    "    shape=(U, I),\n",
    "    dtype=np.float32\n",
    ")\n",
    "\n",
    "C = (R.T @ R).tocsr()\n",
    "C.setdiag(0); C.eliminate_zeros()\n",
    "\n",
    "M_SIM = 50\n",
    "item_sim_map = {}\n",
    "for iid in range(I):\n",
    "    a, b = C.indptr[iid], C.indptr[iid+1]\n",
    "    if a == b:\n",
    "        item_sim_map[iid] = []\n",
    "        continue\n",
    "    neigh = C.indices[a:b]\n",
    "    vals  = C.data[a:b]\n",
    "    if len(neigh) > M_SIM:\n",
    "        top = np.argpartition(-vals, M_SIM)[:M_SIM]\n",
    "        neigh, vals = neigh[top], vals[top]\n",
    "    order = np.argsort(-vals)\n",
    "    item_sim_map[iid] = neigh[order].tolist()\n",
    "\n",
    "print(f\"[item-sim] built for I={I:,}. Example of item 0:\", item_sim_map.get(0, [])[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ceabb15c9b1202",
   "metadata": {},
   "source": [
    "### 3.1 Create 100-user candidate subset\n",
    "\n",
    "To keep the LLM experiments lightweight, I select 100 users who have both validation and test items, and save their candidate pools plus val/test targets into `candidates_subset100/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c31f1680ec89641",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T03:46:34.980755Z",
     "start_time": "2025-11-28T03:46:34.734140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users with val+test: 59487\n",
      "Selected 100 users: 100\n",
      "Saving 100-user candidates to: C:\\Users\\carlk\\OneDrive\\Documents\\uoft\\ECE1508H F\\Project\\candidates_subset100\n",
      "✓ Saved 100-user subset to C:\\Users\\carlk\\OneDrive\\Documents\\uoft\\ECE1508H F\\Project\\candidates_subset100\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "SPLITS = BASE / \"splits\"\n",
    "\n",
    "train_idx = pd.read_parquet(SPLITS / \"train_indexed.parquet\")\n",
    "val_idx   = pd.read_parquet(SPLITS / \"val_targets_indexed.parquet\")\n",
    "test_idx  = pd.read_parquet(SPLITS / \"test_targets_indexed.parquet\")\n",
    "\n",
    "users_with_val  = set(val_idx['uid'].unique())\n",
    "users_with_test = set(test_idx['uid'].unique())\n",
    "candidate_users = sorted(users_with_val & users_with_test)\n",
    "\n",
    "subset_users = candidate_users[:100]\n",
    "\n",
    "print(\"Users with val+test:\", len(candidate_users))\n",
    "print(\"Selected 100 users:\", len(subset_users))\n",
    "\n",
    "train_sub = train_idx[train_idx['uid'].isin(subset_users)].copy()\n",
    "val_tgt   = val_idx[val_idx['uid'].isin(subset_users)].copy()\n",
    "test_tgt  = test_idx[test_idx['uid'].isin(subset_users)].copy()\n",
    "\n",
    "item_pop_series = train_sub['iid'].value_counts().astype(float)\n",
    "item_pop_series /= item_pop_series.max()\n",
    "item_pop = item_pop_series.to_dict()\n",
    "item_popular = sorted(item_pop.items(), key=lambda x: -x[1])\n",
    "\n",
    "def build_pool_for_user(uid, k=50):\n",
    "    seen = set(train_sub.loc[train_sub['uid'] == uid, 'iid'].astype(int))\n",
    "    pool = [int(i) for i, _ in item_popular if i not in seen][:k]\n",
    "    return pool\n",
    "\n",
    "rows = []\n",
    "for u in subset_users:\n",
    "    rows.append({\n",
    "        \"uid\": int(u),\n",
    "        \"candidates\": build_pool_for_user(int(u), k=50)\n",
    "    })\n",
    "\n",
    "cand = pd.DataFrame(rows)\n",
    "\n",
    "OUT = BASE / \"candidates_subset100\"\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "print(\"Saving 100-user candidates to:\", OUT)\n",
    "\n",
    "cand.to_parquet(OUT / \"val.parquet\",  index=False)\n",
    "cand.to_parquet(OUT / \"test.parquet\", index=False)\n",
    "\n",
    "val_tgt.to_parquet(OUT / \"val_targets_indexed.parquet\",  index=False)\n",
    "test_tgt.to_parquet(OUT / \"test_targets_indexed.parquet\", index=False)\n",
    "\n",
    "print(\"✓ Saved 100-user subset to\", OUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f19e2138ce620ea",
   "metadata": {},
   "source": [
    "## 4. Force-add ground-truth items into candidate pools\n",
    "\n",
    "For the 100-user subset, I guarantee that each user's validation and test items are always included in their candidate list. I load `val.parquet` / `test.parquet`, union candidates with the corresponding ground-truth items, and overwrite the candidate files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d683c454d4a3799f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T03:46:35.143765Z",
     "start_time": "2025-11-28T03:46:34.991859Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cand_val : (100, 2)\n",
      "Loaded cand_test: (100, 2)\n",
      "Loaded val_tgt  : (100, 5)\n",
      "Loaded test_tgt : (100, 5)\n",
      "✓ Ground-truth items have been forced into candidate pools.\n",
      "  New cand_val shape : (100, 2)\n",
      "  (val / test now share exactly the same candidate pools)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(r\"C:\\Users\\carlk\\OneDrive\\Documents\\uoft\\ECE1508H F\\Project\")\n",
    "CANDS = BASE / \"candidates_subset100\"\n",
    "\n",
    "cand_val  = pd.read_parquet(CANDS / \"val.parquet\")                   # [uid, candidates]\n",
    "cand_test = pd.read_parquet(CANDS / \"test.parquet\")                  # [uid, candidates]\n",
    "\n",
    "val_tgt   = pd.read_parquet(CANDS / \"val_targets_indexed.parquet\")   # [uid, iid, ...]\n",
    "test_tgt  = pd.read_parquet(CANDS / \"test_targets_indexed.parquet\")  # [uid, iid, ...]\n",
    "\n",
    "print(\"Loaded cand_val :\", cand_val.shape)\n",
    "print(\"Loaded cand_test:\", cand_test.shape)\n",
    "print(\"Loaded val_tgt  :\", val_tgt.shape)\n",
    "print(\"Loaded test_tgt :\", test_tgt.shape)\n",
    "\n",
    "cand_map = {int(row.uid): list(row.candidates) for _, row in cand_val.iterrows()}\n",
    "\n",
    "for uid in sorted(cand_map.keys()):\n",
    "    uid = int(uid)\n",
    "\n",
    "\n",
    "    val_items  = set(val_tgt[val_tgt[\"uid\"] == uid][\"iid\"].astype(int).tolist())\n",
    "    test_items = set(test_tgt[test_tgt[\"uid\"] == uid][\"iid\"].astype(int).tolist())\n",
    "    gt_items   = val_items | test_items\n",
    "\n",
    "    cur_list = cand_map[uid]\n",
    "    cur_set  = set(int(i) for i in cur_list)\n",
    "\n",
    "    added = 0\n",
    "    for g in gt_items:\n",
    "        g = int(g)\n",
    "        if g not in cur_set:\n",
    "            cur_list.append(g)\n",
    "            cur_set.add(g)\n",
    "            added += 1\n",
    "\n",
    "    cand_map[uid] = cur_list\n",
    "\n",
    "cand_fixed = pd.DataFrame(\n",
    "    [{\"uid\": uid, \"candidates\": cand_map[uid]} for uid in sorted(cand_map.keys())]\n",
    ")\n",
    "\n",
    "cand_fixed.to_parquet(CANDS / \"val.parquet\", index=False)\n",
    "cand_fixed.to_parquet(CANDS / \"test.parquet\", index=False)\n",
    "\n",
    "print(\"✓ Ground-truth items have been forced into candidate pools.\")\n",
    "print(\"  New cand_val shape :\", cand_fixed.shape)\n",
    "print(\"  (val / test now share exactly the same candidate pools)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e723c78834b0306",
   "metadata": {},
   "source": [
    "## 5. Truncate training history to last 5 positives per user\n",
    "\n",
    "To make the user histories more comparable to MovieLens and to control sequence length, I keep at most 5 most recent positives per user in `train_indexed.parquet`. The original file is backed up as `train_indexed_full_backup.parquet`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f52008f2fc5265",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T03:46:36.030847Z",
     "start_time": "2025-11-28T03:46:35.163320Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train_indexed shape: (690814, 5)\n",
      "\n",
      "[Old] train positives per user:\n",
      "count    60597.000000\n",
      "mean        11.400135\n",
      "std         27.487630\n",
      "min          3.000000\n",
      "25%          4.000000\n",
      "50%          6.000000\n",
      "75%         11.000000\n",
      "max       2325.000000\n",
      "Name: iid, dtype: float64\n",
      "\n",
      "[New] train positives per user (after truncation to <=5):\n",
      "count    60597.000000\n",
      "mean         4.460617\n",
      "std          0.799503\n",
      "min          3.000000\n",
      "25%          4.000000\n",
      "50%          5.000000\n",
      "75%          5.000000\n",
      "max          5.000000\n",
      "Name: iid, dtype: float64\n",
      "\n",
      "Check min/new max history length per user:\n",
      "  min = 3   max = 5\n",
      "\n",
      "Backup saved to: C:\\Users\\carlk\\OneDrive\\Documents\\uoft\\ECE1508H F\\Project\\splits\\train_indexed_full_backup.parquet\n",
      "\n",
      "✔ Overwritten train_indexed.parquet with truncated history.\n",
      "Final train_indexed shape: (270300, 5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(r\"C:\\Users\\carlk\\OneDrive\\Documents\\uoft\\ECE1508H F\\Project\")\n",
    "SPLITS = BASE / \"splits\"\n",
    "\n",
    "train_path = SPLITS / \"train_indexed.parquet\"\n",
    "train_idx = pd.read_parquet(train_path)\n",
    "\n",
    "print(\"Original train_indexed shape:\", train_idx.shape)\n",
    "\n",
    "old_counts = train_idx.groupby(\"uid\")[\"iid\"].size()\n",
    "print(\"\\n[Old] train positives per user:\")\n",
    "print(old_counts.describe())\n",
    "\n",
    "def truncate_history(df: pd.DataFrame, k: int = 5) -> pd.DataFrame:\n",
    "    df_sorted = df.sort_values([\"uid\", \"ts\"])\n",
    "    out = (\n",
    "        df_sorted\n",
    "        .groupby(\"uid\", as_index=False)\n",
    "        .tail(k)\n",
    "        .sort_values([\"uid\", \"ts\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    return out\n",
    "\n",
    "train_trunc = truncate_history(train_idx, k=5)\n",
    "\n",
    "new_counts = train_trunc.groupby(\"uid\")[\"iid\"].size()\n",
    "print(\"\\n[New] train positives per user (after truncation to <=5):\")\n",
    "print(new_counts.describe())\n",
    "\n",
    "print(\"\\nCheck min/new max history length per user:\")\n",
    "print(\"  min =\", int(new_counts.min()), \"  max =\", int(new_counts.max()))\n",
    "\n",
    "backup_path = SPLITS / \"train_indexed_full_backup.parquet\"\n",
    "if not backup_path.exists():\n",
    "    train_idx.to_parquet(backup_path, index=False)\n",
    "    print(\"\\nBackup saved to:\", backup_path)\n",
    "else:\n",
    "    print(\"\\nBackup already exists at:\", backup_path)\n",
    "\n",
    "train_trunc.to_parquet(train_path, index=False)\n",
    "print(\"\\n✔ Overwritten train_indexed.parquet with truncated history.\")\n",
    "print(\"Final train_indexed shape:\", train_trunc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a901d268501181a7",
   "metadata": {},
   "source": [
    "## 6. Sanity checks on 100-user subset and candidate pools\n",
    "\n",
    "This cell verifies that:\n",
    "\n",
    "1. The 100 selected users appear in train/val/test.\n",
    "2. Per-user interaction counts are reasonable.\n",
    "3. Validation and test candidate pools share the same set of candidates for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8327673ca8ae29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T03:46:36.182259Z",
     "start_time": "2025-11-28T03:46:36.044623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train_idx: (270300, 5)\n",
      "Loaded val_idx_sub: (100, 5)\n",
      "Loaded test_idx_sub: (100, 5)\n",
      "Loaded cand_val: (100, 2)\n",
      "Loaded cand_test: (100, 2)\n",
      "\n",
      "[1] User counts\n",
      "train users in subset: 100\n",
      "val users: 100\n",
      "test users: 100\n",
      "\n",
      "[2] Per-user counts (subset)\n",
      "Train counts stats:\n",
      " count    100.000000\n",
      "mean       4.600000\n",
      "std        0.738549\n",
      "min        3.000000\n",
      "25%        4.750000\n",
      "50%        5.000000\n",
      "75%        5.000000\n",
      "max        5.000000\n",
      "Name: iid, dtype: float64\n",
      "Val counts unique values: [1]\n",
      "Test counts unique values: [1]\n",
      "\n",
      "[3] Candidate rows per user\n",
      "val candidate users: 100\n",
      "test candidate users: 100\n",
      "\n",
      "[4] Same candidate pool for val & test?\n",
      "same uid order : True\n",
      "same pools     : True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(r\"C:\\Users\\carlk\\OneDrive\\Documents\\uoft\\ECE1508H F\\Project\")\n",
    "SPLITS = BASE / \"splits\"\n",
    "CANDS  = BASE / \"candidates_subset100\"\n",
    "\n",
    "train_idx = pd.read_parquet(SPLITS / \"train_indexed.parquet\")\n",
    "val_idx_sub  = pd.read_parquet(CANDS / \"val_targets_indexed.parquet\")\n",
    "test_idx_sub = pd.read_parquet(CANDS / \"test_targets_indexed.parquet\")\n",
    "\n",
    "cand_val  = pd.read_parquet(CANDS / \"val.parquet\")\n",
    "cand_test = pd.read_parquet(CANDS / \"test.parquet\")\n",
    "\n",
    "print(\"Loaded train_idx:\", train_idx.shape)\n",
    "print(\"Loaded val_idx_sub:\",  val_idx_sub.shape)\n",
    "print(\"Loaded test_idx_sub:\", test_idx_sub.shape)\n",
    "print(\"Loaded cand_val:\",  cand_val.shape)\n",
    "print(\"Loaded cand_test:\", cand_test.shape)\n",
    "\n",
    "users_train = set(train_idx['uid'].unique())\n",
    "users_val   = set(val_idx_sub['uid'].unique())\n",
    "users_test  = set(test_idx_sub['uid'].unique())\n",
    "\n",
    "subset_users = users_val\n",
    "print(\"\\n[1] User counts\")\n",
    "print(\"train users in subset:\", len(users_train & subset_users))\n",
    "print(\"val users:\",  len(users_val))\n",
    "print(\"test users:\", len(users_test))\n",
    "\n",
    "train_sub = train_idx[train_idx['uid'].isin(subset_users)]\n",
    "\n",
    "train_counts = train_sub.groupby(\"uid\")['iid'].nunique()\n",
    "val_counts   = val_idx_sub.groupby(\"uid\")['iid'].nunique()\n",
    "test_counts  = test_idx_sub.groupby(\"uid\")['iid'].nunique()\n",
    "\n",
    "print(\"\\n[2] Per-user counts (subset)\")\n",
    "print(\"Train counts stats:\\n\", train_counts.describe())\n",
    "print(\"Val counts unique values:\",  val_counts.unique())\n",
    "print(\"Test counts unique values:\", test_counts.unique())\n",
    "\n",
    "print(\"\\n[3] Candidate rows per user\")\n",
    "print(\"val candidate users:\",  cand_val['uid'].nunique())\n",
    "print(\"test candidate users:\", cand_test['uid'].nunique())\n",
    "\n",
    "cand_val_sorted  = cand_val.sort_values(\"uid\").reset_index(drop=True)\n",
    "cand_test_sorted = cand_test.sort_values(\"uid\").reset_index(drop=True)\n",
    "\n",
    "same_uid_order = (cand_val_sorted['uid'].tolist() ==\n",
    "                  cand_test_sorted['uid'].tolist())\n",
    "same_pools = all(\n",
    "    list(v) == list(t)\n",
    "    for v, t in zip(cand_val_sorted['candidates'],\n",
    "                    cand_test_sorted['candidates'])\n",
    ")\n",
    "\n",
    "print(\"\\n[4] Same candidate pool for val & test?\")\n",
    "print(\"same uid order :\", same_uid_order)\n",
    "print(\"same pools     :\", same_pools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e84e6c24f8eb207",
   "metadata": {},
   "source": [
    "## 7. Export final splits and candidates to CSV\n",
    "\n",
    "I export the latest (truncated) splits and the 100-user candidate pools to `csv_export/` as CSV files:\n",
    "\n",
    "1.`train_indexed.csv`, `val_targets_indexed.csv`, `test_targets_indexed.csv`\n",
    "2.`user_id_map.csv`, `item_id_map.csv`\n",
    "3.`candidates_val.csv`, `candidates_test.csv`\n",
    "\n",
    "These are the files that both the recommender baseline and the LLM prompts will use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc6003f880cb9e85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T03:46:38.257122Z",
     "start_time": "2025-11-28T03:46:36.193982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading latest (TRUNCATED) splits...\n",
      "\n",
      "✓ All CSV exported to: C:\\Users\\carlk\\OneDrive\\Documents\\uoft\\ECE1508H F\\Project\\csv_export\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(\"C:/Users/carlk/OneDrive/Documents/uoft/ECE1508H F/Project\")\n",
    "SPLITS = BASE / \"splits\"\n",
    "CAND = BASE / \"candidates_subset100\"\n",
    "\n",
    "OUT = BASE / \"csv_export\"\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Loading latest (TRUNCATED) splits...\")\n",
    "\n",
    "train_idx = pd.read_parquet(SPLITS / \"train_indexed.parquet\")\n",
    "val_tgt   = pd.read_parquet(SPLITS / \"val_targets_indexed.parquet\")\n",
    "test_tgt  = pd.read_parquet(SPLITS / \"test_targets_indexed.parquet\")\n",
    "\n",
    "user_map  = pd.read_parquet(SPLITS / \"user_id_map.parquet\")\n",
    "item_map  = pd.read_parquet(SPLITS / \"item_id_map.parquet\")\n",
    "\n",
    "cand_val  = pd.read_parquet(CAND / \"val.parquet\")\n",
    "cand_test = pd.read_parquet(CAND / \"test.parquet\")\n",
    "\n",
    "train_idx.to_csv(OUT / \"train_indexed.csv\", index=False)\n",
    "val_tgt.to_csv(OUT / \"val_targets_indexed.csv\", index=False)\n",
    "test_tgt.to_csv(OUT / \"test_targets_indexed.csv\", index=False)\n",
    "\n",
    "user_map.to_csv(OUT / \"user_id_map.csv\", index=False)\n",
    "item_map.to_csv(OUT / \"item_id_map.csv\", index=False)\n",
    "\n",
    "cand_val.to_csv(OUT / \"candidates_val.csv\", index=False)\n",
    "cand_test.to_csv(OUT / \"candidates_test.csv\", index=False)\n",
    "\n",
    "print(\"\\n✓ All CSV exported to:\", OUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39399e9aee3d82d",
   "metadata": {},
   "source": [
    "## 8. Build simple item-level metadata (title + one review field)\n",
    "\n",
    "I join the `item_id_map` with the original Amazon CSV to get an initial metadata table:\n",
    "\n",
    "1. `itemId` (string ID from Kaggle)\n",
    "2. `iid` (indexed item ID)\n",
    "3. `title`\n",
    "4. one raw text field (either `review/summary` or `review/text`, depending on availability)\n",
    "\n",
    "The result is saved as `csv_export/amazonbooks_metadata_with_title_desc.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5107164341df49c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T04:50:40.613964Z",
     "start_time": "2025-11-28T04:49:55.087790Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_map: (26522, 2)\n",
      "raw metadata: (3000000, 10)\n",
      "metadata cleaned: (3000000, 3)\n",
      "Final merged shape: (2126508, 4)\n",
      "\n",
      "Saved final metadata to: C:\\Users\\carlk\\OneDrive\\Documents\\uoft\\ECE1508H F\\Project\\csv_export\\amazonbooks_metadata_with_title_desc.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(r\"C:/Users/carlk/OneDrive/Documents/uoft/ECE1508H F/Project\")\n",
    "\n",
    "item_map = pd.read_parquet(BASE / \"splits\" / \"item_id_map.parquet\")\n",
    "print(\"item_map:\", item_map.shape)\n",
    "\n",
    "meta_path = BASE / \"Books_rating.csv\"\n",
    "raw = pd.read_csv(meta_path, dtype=str)\n",
    "print(\"raw metadata:\", raw.shape)\n",
    "\n",
    "description_col = \"review/summary\" if \"review/summary\" in raw.columns else \"review/text\"\n",
    "\n",
    "metadata = raw[[\"Id\", \"Title\", description_col]].copy()\n",
    "metadata = metadata.rename(columns={\n",
    "    \"Id\": \"itemId\",\n",
    "    \"Title\": \"title\",\n",
    "    description_col: \"description\"\n",
    "})\n",
    "print(\"metadata cleaned:\", metadata.shape)\n",
    "\n",
    "merged = item_map.merge(metadata, on=\"itemId\", how=\"left\")\n",
    "print(\"Final merged shape:\", merged.shape)\n",
    "\n",
    "out_file = BASE / \"csv_export\" / \"amazonbooks_metadata_with_title_desc.csv\"\n",
    "merged.to_csv(out_file, index=False)\n",
    "\n",
    "print(\"\\nSaved final metadata to:\", out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da80832b4aa053db",
   "metadata": {},
   "source": [
    "### 8.1 Quick quality checks on metadata\n",
    "\n",
    "I load `amazonbooks_metadata_with_title_desc.csv` and check:\n",
    "\n",
    "1. required columns (`itemId`, `iid`, `title`, `description`)\n",
    "2. uniqueness of `itemId` / `iid`\n",
    "3. missing titles or descriptions\n",
    "4. a small preview of the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbc79548d046263",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T05:00:01.520205Z",
     "start_time": "2025-11-28T04:59:59.110876Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: C:\\Users\\carlk\\OneDrive\\Documents\\uoft\\ECE1508H F\\Project\\csv_export\\amazonbooks_metadata_with_title_desc.csv\n",
      "Loaded shape: (2126508, 4)\n",
      "Columns: ['itemId', 'iid', 'title', 'description']\n",
      "\n",
      "[1] Check required columns\n",
      "  itemId: OK\n",
      "  iid: OK\n",
      "  title: OK\n",
      "  description: OK\n",
      "\n",
      "[2] Uniqueness checks\n",
      "  unique itemId: 26522\n",
      "  rows (should match if no duplicated itemId): 2126508\n",
      "  unique iid    : 26522\n",
      "\n",
      "[3] Missing values\n",
      "  missing title       : 185\n",
      "  missing description : 330\n",
      "\n",
      "[4] Sample rows\n",
      "       itemId iid                  title  \\\n",
      "0  0001047655   0  The Prodigal Daughter   \n",
      "1  0001047655   0  The Prodigal Daughter   \n",
      "2  0001047655   0  The Prodigal Daughter   \n",
      "3  0001047655   0  The Prodigal Daughter   \n",
      "4  0001047655   0  The Prodigal Daughter   \n",
      "5  0001047655   0  The Prodigal Daughter   \n",
      "6  0001047655   0  The Prodigal Daughter   \n",
      "7  0001047655   0  The Prodigal Daughter   \n",
      "8  0001047655   0  The Prodigal Daughter   \n",
      "9  0001047655   0  The Prodigal Daughter   \n",
      "\n",
      "                               description  \n",
      "0                               Who Cares?  \n",
      "1                LA OBRA MAESTRA DE ARCHER  \n",
      "2                  Extremly desapointing!!  \n",
      "3                             A great read  \n",
      "4                    The Prodigal Daughter  \n",
      "5  The Prodigal Daughter by Jeffrey Archer  \n",
      "6                          Worth your time  \n",
      "7                         Favorite author.  \n",
      "8                    The Prodical Daughter  \n",
      "9                      A well written book  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(r\"C:/Users/carlk/OneDrive/Documents/uoft/ECE1508H F/Project\")\n",
    "meta_file = BASE / \"csv_export\" / \"amazonbooks_metadata_with_title_desc.csv\"\n",
    "\n",
    "print(\"Loading:\", meta_file)\n",
    "df = pd.read_csv(meta_file, dtype=str)\n",
    "print(\"Loaded shape:\", df.shape)\n",
    "print(\"Columns:\", list(df.columns))\n",
    "\n",
    "print(\"\\n[1] Check required columns\")\n",
    "for col in [\"itemId\", \"iid\", \"title\", \"description\"]:\n",
    "    print(f\"  {col}: {'OK' if col in df.columns else 'MISSING'}\")\n",
    "\n",
    "print(\"\\n[2] Uniqueness checks\")\n",
    "print(\"  unique itemId:\", df[\"itemId\"].nunique())\n",
    "print(\"  rows (should match if no duplicated itemId):\", len(df))\n",
    "print(\"  unique iid    :\", df[\"iid\"].nunique())\n",
    "\n",
    "print(\"\\n[3] Missing values\")\n",
    "print(\"  missing title       :\", df[\"title\"].isna().sum())\n",
    "print(\"  missing description :\", df[\"description\"].isna().sum())\n",
    "\n",
    "print(\"\\n[4] Sample rows\")\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d324a21d8b27ad6",
   "metadata": {},
   "source": [
    "### 8.2 Inspect raw Kaggle columns\n",
    "\n",
    "I briefly inspect the original `Books_rating.csv` columns to decide which text field to use as review content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af696495b931046c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T04:38:52.720067Z",
     "start_time": "2025-11-28T04:38:15.807412Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'Title', 'Price', 'User_id', 'profileName', 'review/helpfulness',\n",
      "       'review/score', 'review/time', 'review/summary', 'review/text'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw = pd.read_csv(\"C:/Users/carlk/OneDrive/Documents/uoft/ECE1508H F/Project/Books_rating.csv\")\n",
    "print(raw.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c84da050237a97b",
   "metadata": {},
   "source": [
    "## 9. Merge multiple reviews into short per-item descriptions\n",
    "\n",
    "To make the Amazon metadata more LLM-friendly, I build a cleaned, merged description per `iid`:\n",
    "\n",
    "1. Read the original Kaggle CSV and select (`itemId`, `Title`, review text).\n",
    "2. Join with `item_id_map` so every row has an `iid`.\n",
    "3. For each title, we try to pick different reviews for different `iid`s with the same title, so the LLM can tell them apart.\n",
    "4. For each `iid`, we:\n",
    "   - select up to 5 informative reviews,\n",
    "   - concatenate them with `\" \"` as separator,\n",
    "   - decode HTML entities (e.g. `&quot;` → `\"`)\n",
    "   - truncate the final description to at most 400 characters without cutting words in half.\n",
    "\n",
    "The final table (`itemId`, `iid`, `title`, `description`) is saved as:\n",
    "\n",
    "`csv_export/amazonbooks_metadata_merged_per_iid_clean.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13778cbd33f094bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T16:22:32.452936Z",
     "start_time": "2025-11-29T16:21:35.899161Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_map: (26522, 2)\n",
      "raw rating csv: (3000000, 10)\n",
      "after dropping empty reviews: (2999593, 3)\n",
      "after merging with item_map: (2126178, 4)\n",
      "final metadata shape: (26521, 4)\n",
      "       itemId    iid                               title  \\\n",
      "0  0826414346   8253            Dr. Seuss: American Icon   \n",
      "1  0789480662   7476   Eyewitness Travel Guide to Europe   \n",
      "2  006000486X    143             Tess and the Highlander   \n",
      "3  0671551345   4970  Night World: Daughters Of Darkness   \n",
      "4  B000N7612G  23576                    The Food Of Love   \n",
      "\n",
      "                                         description  \n",
      "0  And to think that I read it on the tram! Essen...  \n",
      "1  Great travel guide to Europe! nice eye candy, ...  \n",
      "2  My new favorite book from the Avon True Romanc...  \n",
      "3  i love LJ Smith! best of the Night World books...  \n",
      "4  Book of Chance The food is sexier than the sex...  \n",
      "\n",
      "Saved merged iid-level metadata to: C:\\Users\\carlk\\OneDrive\\Documents\\uoft\\ECE1508H F\\Project\\csv_export\\amazonbooks_metadata_merged_per_iid_clean.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import html\n",
    "\n",
    "BASE = Path(r\"C:/Users/carlk/OneDrive/Documents/uoft/ECE1508H F/Project\")\n",
    "\n",
    "ITEM_MAP_PATH = BASE / \"splits\" / \"item_id_map.parquet\"\n",
    "RATING_CSV_PATH = BASE / \"Books_rating.csv\"\n",
    "\n",
    "OUT_PATH = BASE / \"csv_export\" / \"amazonbooks_metadata_merged_per_iid_clean.csv\"\n",
    "\n",
    "# hyper-parameters\n",
    "REVIEWS_PER_IID = 5\n",
    "MAX_CHARS = 400\n",
    "\n",
    "item_map = pd.read_parquet(ITEM_MAP_PATH)   # columns: ['itemId', 'iid']\n",
    "print(\"item_map:\", item_map.shape)\n",
    "\n",
    "raw = pd.read_csv(RATING_CSV_PATH, dtype=str)\n",
    "print(\"raw rating csv:\", raw.shape)\n",
    "\n",
    "if \"review/summary\" in raw.columns:\n",
    "    desc_col = \"review/summary\"\n",
    "elif \"review/text\" in raw.columns:\n",
    "    desc_col = \"review/text\"\n",
    "else:\n",
    "    raise ValueError(\"No suitable review column found in Books_rating.csv\")\n",
    "\n",
    "df = raw[[\"Id\", \"Title\", desc_col]].rename(\n",
    "    columns={\n",
    "        \"Id\": \"itemId\",\n",
    "        \"Title\": \"title\",\n",
    "        desc_col: \"review\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# drop empty / NaN reviews\n",
    "df[\"review\"] = df[\"review\"].fillna(\"\").str.strip()\n",
    "df = df[df[\"review\"] != \"\"]\n",
    "print(\"after dropping empty reviews:\", df.shape)\n",
    "\n",
    "df = df.merge(item_map, on=\"itemId\", how=\"inner\")\n",
    "# columns: itemId, title, review, iid\n",
    "print(\"after merging with item_map:\", df.shape)\n",
    "\n",
    "rows = []\n",
    "\n",
    "for title, g_title in df.groupby(\"title\", sort=False):\n",
    "    g_title = g_title.sample(frac=1.0, random_state=42)\n",
    "    used_idx = set()\n",
    "\n",
    "    for iid, g_iid in g_title.groupby(\"iid\", sort=False):\n",
    "        own = g_iid[~g_iid.index.isin(used_idx)]\n",
    "        selected = own.head(REVIEWS_PER_IID)\n",
    "\n",
    "        used_idx.update(selected.index)\n",
    "\n",
    "        if len(selected) < REVIEWS_PER_IID:\n",
    "            need = REVIEWS_PER_IID - len(selected)\n",
    "            others = g_title[~g_title.index.isin(used_idx)]\n",
    "            extra = others.head(need)\n",
    "            selected = pd.concat([selected, extra])\n",
    "            used_idx.update(extra.index)\n",
    "\n",
    "        if selected.empty:\n",
    "            continue\n",
    "\n",
    "        text = \" \".join(selected[\"review\"].tolist())\n",
    "\n",
    "        text = html.unescape(text)\n",
    "\n",
    "        if len(text) > MAX_CHARS:\n",
    "            words = text.split()\n",
    "            acc = []\n",
    "            cur_len = 0\n",
    "            for w in words:\n",
    "                add_len = len(w) + (1 if acc else 0)  # plus space if not first word\n",
    "                if cur_len + add_len > MAX_CHARS:\n",
    "                    break\n",
    "                acc.append(w)\n",
    "                cur_len += add_len\n",
    "            text = \" \".join(acc)\n",
    "\n",
    "        rows.append({\n",
    "            \"itemId\": selected[\"itemId\"].iloc[0],\n",
    "            \"iid\": int(iid),\n",
    "            \"title\": title,\n",
    "            \"description\": text\n",
    "        })\n",
    "\n",
    "meta_final = pd.DataFrame(rows)\n",
    "print(\"final metadata shape:\", meta_final.shape)\n",
    "print(meta_final.head(5))\n",
    "\n",
    "OUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "meta_final.to_csv(OUT_PATH, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"\\nSaved merged iid-level metadata to:\", OUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
